{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\n\n!pip install torch transformers numpy scikit-learn pandas simpletransformers","metadata":{"execution":{"iopub.status.busy":"2023-05-08T03:06:33.731773Z","iopub.execute_input":"2023-05-08T03:06:33.732221Z","iopub.status.idle":"2023-05-08T03:06:43.036626Z","shell.execute_reply.started":"2023-05-08T03:06:33.732189Z","shell.execute_reply":"2023-05-08T03:06:43.035523Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.0.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.28.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.23.5)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.2)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (1.5.3)\nRequirement already satisfied: simpletransformers in /opt/conda/lib/python3.10/site-packages (0.63.11)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.11.0)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.5.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.11.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.28.2)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.64.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.3.23)\nRequirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.2.0)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.9.3)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.1.0)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3)\nRequirement already satisfied: seqeval in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (1.2.2)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (0.1.98)\nRequirement already satisfied: tensorboard in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (2.11.2)\nRequirement already satisfied: wandb>=0.10.32 in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (0.15.0)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (2.1.0)\nRequirement already satisfied: streamlit in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (1.22.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (1.4.4)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (1.20.0)\nRequirement already satisfied: pathtools in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (0.1.2)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (0.4.0)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (5.9.4)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (59.8.0)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (3.1.31)\nRequirement already satisfied: Click!=8.0.0,>=7.0 in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (8.1.3)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (1.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.1.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2022.12.7)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->simpletransformers) (3.8.4)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets->simpletransformers) (0.18.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets->simpletransformers) (0.3.6)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->simpletransformers) (10.0.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->simpletransformers) (3.2.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->simpletransformers) (0.70.14)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from datasets->simpletransformers) (2023.4.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.2)\nRequirement already satisfied: tornado>=6.0.3 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (6.2)\nRequirement already satisfied: blinker>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (1.6.2)\nRequirement already satisfied: pympler>=0.9 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (1.0.1)\nRequirement already satisfied: importlib-metadata>=1.4 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (6.0.1)\nRequirement already satisfied: watchdog in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (3.0.0)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (9.5.0)\nRequirement already satisfied: altair<5,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (4.2.2)\nRequirement already satisfied: pydeck>=0.1.dev5 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (0.8.1b0)\nRequirement already satisfied: cachetools>=4.0 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (5.3.0)\nRequirement already satisfied: toml in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (0.10.2)\nRequirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (13.3.3)\nRequirement already satisfied: tzlocal>=1.1 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (4.3)\nRequirement already satisfied: tenacity<9,>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (8.2.2)\nRequirement already satisfied: validators>=0.2 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (0.20.0)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nRequirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard->simpletransformers) (1.53.0)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard->simpletransformers) (0.4.6)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard->simpletransformers) (2.17.2)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard->simpletransformers) (3.4.3)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard->simpletransformers) (2.2.3)\nRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.10/site-packages (from tensorboard->simpletransformers) (0.40.0)\nRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard->simpletransformers) (0.6.1)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard->simpletransformers) (1.8.1)\nRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard->simpletransformers) (1.4.0)\nRequirement already satisfied: toolz in /opt/conda/lib/python3.10/site-packages (from altair<5,>=3.2.0->streamlit->simpletransformers) (0.12.0)\nRequirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.10/site-packages (from altair<5,>=3.2.0->streamlit->simpletransformers) (4.17.3)\nRequirement already satisfied: entrypoints in /opt/conda/lib/python3.10/site-packages (from altair<5,>=3.2.0->streamlit->simpletransformers) (0.4)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->simpletransformers) (22.2.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->simpletransformers) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->simpletransformers) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->simpletransformers) (1.8.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->simpletransformers) (1.3.3)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->simpletransformers) (6.0.4)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb>=0.10.32->simpletransformers) (4.0.10)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->simpletransformers) (4.9)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->simpletransformers) (0.2.8)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->simpletransformers) (1.3.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata>=1.4->streamlit->simpletransformers) (3.15.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->streamlit->simpletransformers) (2.15.0)\nRequirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->streamlit->simpletransformers) (2.2.0)\nRequirement already satisfied: pytz-deprecation-shim in /opt/conda/lib/python3.10/site-packages (from tzlocal>=1.1->streamlit->simpletransformers) (0.1.0.post0)\nRequirement already satisfied: decorator>=3.4.0 in /opt/conda/lib/python3.10/site-packages (from validators>=0.2->streamlit->simpletransformers) (5.1.1)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb>=0.10.32->simpletransformers) (5.0.0)\nRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<5,>=3.2.0->streamlit->simpletransformers) (0.19.3)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=10.11.0->streamlit->simpletransformers) (0.1.2)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->simpletransformers) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->simpletransformers) (3.2.2)\nRequirement already satisfied: tzdata in /opt/conda/lib/python3.10/site-packages (from pytz-deprecation-shim->tzlocal>=1.1->streamlit->simpletransformers) (2023.3)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport torch \nimport numpy as np\nfrom torch.utils.data import DataLoader\nfrom transformers import AutoTokenizer, AutoModelForTokenClassification\nfrom tqdm import tqdm\nfrom torch.optim import SGD\nimport csv\nfrom sklearn.metrics import classification_report\nimport warnings\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2023-05-08T03:06:43.040560Z","iopub.execute_input":"2023-05-08T03:06:43.040851Z","iopub.status.idle":"2023-05-08T03:06:43.047010Z","shell.execute_reply.started":"2023-05-08T03:06:43.040825Z","shell.execute_reply":"2023-05-08T03:06:43.045816Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def read_file(file_path):\n    with open(file_path, encoding=\"maccentraleurope\") as f:\n        examples = {\"sents\": [], \"labels\": []}\n        sents = []\n        labels = []\n        for line in f:\n            if line.startswith(\"-DOCSTART-\") or line == \"\" or line == \"\\n\":\n                if sents:\n                    examples[\"sents\"].append(' '.join(sents[:512]))\n                    examples[\"labels\"].append(' '.join(labels[:512]))\n                    sents = []\n                    labels = []\n            else:\n                splits = line.split(\" \")\n                sents.append(splits[0])\n                if len(splits) > 1:\n                    labels.append(splits[-1].replace(\"\\n\", \"\"))\n                else:\n                    # Examples could have no label for mode = \"test\"\n                    labels.append(\"O\")\n    return examples\ntrain = read_file('/kaggle/input/d/rohithkoritala99/sp-ner/esp.train')\ntesta = read_file('/kaggle/input/d/rohithkoritala99/sp-ner/esp.testa')\ntestb = read_file('/kaggle/input/d/rohithkoritala99/sp-ner/esp.testb')","metadata":{"execution":{"iopub.status.busy":"2023-05-08T03:06:43.048541Z","iopub.execute_input":"2023-05-08T03:06:43.049142Z","iopub.status.idle":"2023-05-08T03:06:43.369289Z","shell.execute_reply.started":"2023-05-08T03:06:43.049110Z","shell.execute_reply":"2023-05-08T03:06:43.368392Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.DataFrame({'text': train['sents'], 'labels': train['labels']})\ntesta_df = pd.DataFrame({'text': testa['sents'], 'labels': testa['labels']})\ntestb_df = pd.DataFrame({'text': testb['sents'], 'labels': testb['labels']})\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-08T03:06:43.371861Z","iopub.execute_input":"2023-05-08T03:06:43.372235Z","iopub.status.idle":"2023-05-08T03:06:43.398373Z","shell.execute_reply.started":"2023-05-08T03:06:43.372203Z","shell.execute_reply":"2023-05-08T03:06:43.397406Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"                                                text  \\\n0         Melbourne ( Australia ) , 25 may ( EFE ) .   \n1                                                  -   \n2  El Abogado General del Estado , Daryl Williams...   \n3  La peticiůn del Abogado General tiene lugar de...   \n4  Esta pŠgina web lleva un mes de existencia , t...   \n\n                                              labels  \n0                  B-LOC O B-LOC O O O O O B-ORG O O  \n1                                                  O  \n2  O B-PER I-PER I-PER I-PER O B-PER I-PER O O O ...  \n3  O O O B-PER I-PER O O O O O O O O B-ORG I-ORG ...  \n4  O O O O O O O O O O O O O O O O O O O O O O O ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Melbourne ( Australia ) , 25 may ( EFE ) .</td>\n      <td>B-LOC O B-LOC O O O O O B-ORG O O</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>El Abogado General del Estado , Daryl Williams...</td>\n      <td>O B-PER I-PER I-PER I-PER O B-PER I-PER O O O ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>La peticiůn del Abogado General tiene lugar de...</td>\n      <td>O O O B-PER I-PER O O O O O O O O B-ORG I-ORG ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Esta pŠgina web lleva un mes de existencia , t...</td>\n      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#tokenizer_cbs = AutoTokenizer.from_pretrained(\"/kaggle/input/sp-bert\", use_auth_token=True)\ntokenizer_mlb = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")","metadata":{"execution":{"iopub.status.busy":"2023-05-08T03:08:39.621218Z","iopub.execute_input":"2023-05-08T03:08:39.621605Z","iopub.status.idle":"2023-05-08T03:08:41.807573Z","shell.execute_reply.started":"2023-05-08T03:08:39.621576Z","shell.execute_reply":"2023-05-08T03:08:41.806658Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd73de1f787d4ad49aab6970d11c8448"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8df82485121b4ca6945b6a140677a676"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe2aa4b02c68489ebface81e2cc3be38"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bfeff17647f44d59852c82c6cfd88b61"}},"metadata":{}}]},{"cell_type":"code","source":"labels = [i.split() for i in train_df['labels'].values.tolist()]\nunique_labels = set()\n\nfor lb in labels:\n        [unique_labels.add(i) for i in lb if i not in unique_labels]\nlabels_to_ids = {k: v for v, k in enumerate(unique_labels)}\nids_to_labels = {v: k for v, k in enumerate(unique_labels)}","metadata":{"execution":{"iopub.status.busy":"2023-05-08T03:08:52.682548Z","iopub.execute_input":"2023-05-08T03:08:52.682937Z","iopub.status.idle":"2023-05-08T03:08:52.718130Z","shell.execute_reply.started":"2023-05-08T03:08:52.682901Z","shell.execute_reply":"2023-05-08T03:08:52.717163Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_all_tokens = False\n\ndef align_label(texts, labels, tokenizer):\n    tokenized_inputs = tokenizer(texts, padding='max_length', max_length=512, truncation=True, return_tensors=\"pt\")\n\n    word_ids = tokenized_inputs.word_ids()\n\n    previous_word_idx = None\n    label_ids = []\n\n    for word_idx in word_ids:\n\n        if word_idx is None:\n            label_ids.append(-100)\n\n        elif word_idx != previous_word_idx:\n            try:\n                label_ids.append(labels_to_ids[labels[word_idx]])\n            except:\n                label_ids.append(-100)\n        else:\n            try:\n                label_ids.append(labels_to_ids[labels[word_idx]] if label_all_tokens else -100)\n            except:\n                label_ids.append(-100)\n        previous_word_idx = word_idx\n\n    return label_ids\n\nclass DataSequence(torch.utils.data.Dataset):\n\n    def __init__(self, df, tokenizer):\n        \n        self.tokenizer = tokenizer\n\n        lb = [i.split() for i in df['labels'].values.tolist()]\n        txt = df['text'].values.tolist()\n        self.texts = [self.tokenizer(str(i),\n                               padding='max_length', max_length = 512, truncation=True, return_tensors=\"pt\") for i in txt]\n        self.labels = [align_label(i,j, self.tokenizer) for i,j in zip(txt, lb)]\n\n    def __len__(self):\n\n        return len(self.labels)\n\n    def get_batch_data(self, idx):\n\n        return self.texts[idx]\n\n    def get_batch_labels(self, idx):\n\n        return torch.LongTensor(self.labels[idx])\n\n    def __getitem__(self, idx):\n\n        batch_data = self.get_batch_data(idx)\n        batch_labels = self.get_batch_labels(idx)\n\n        return batch_data, batch_labels","metadata":{"execution":{"iopub.status.busy":"2023-05-08T03:08:57.289966Z","iopub.execute_input":"2023-05-08T03:08:57.290644Z","iopub.status.idle":"2023-05-08T03:08:57.302353Z","shell.execute_reply.started":"2023-05-08T03:08:57.290610Z","shell.execute_reply":"2023-05-08T03:08:57.300951Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"class MultilingualBert(torch.nn.Module):\n\n    def __init__(self):\n\n        super(MultilingualBert, self).__init__()\n\n        self.conflibert = AutoModelForTokenClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=len(unique_labels))\n\n    def forward(self, input_id, mask, label):\n\n        output = self.conflibert(input_ids=input_id, attention_mask=mask, labels=label, return_dict=False)\n\n        return output","metadata":{"execution":{"iopub.status.busy":"2023-05-08T03:09:03.325099Z","iopub.execute_input":"2023-05-08T03:09:03.325655Z","iopub.status.idle":"2023-05-08T03:09:03.331786Z","shell.execute_reply.started":"2023-05-08T03:09:03.325622Z","shell.execute_reply":"2023-05-08T03:09:03.330898Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"unique_labels","metadata":{"execution":{"iopub.status.busy":"2023-05-08T03:09:06.405905Z","iopub.execute_input":"2023-05-08T03:09:06.406487Z","iopub.status.idle":"2023-05-08T03:09:06.415010Z","shell.execute_reply.started":"2023-05-08T03:09:06.406455Z","shell.execute_reply":"2023-05-08T03:09:06.413926Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"{'B-LOC', 'B-MISC', 'B-ORG', 'B-PER', 'I-LOC', 'I-MISC', 'I-ORG', 'I-PER', 'O'}"},"metadata":{}}]},{"cell_type":"code","source":"warnings.filterwarnings('ignore')\n\ndef train_loop(model, df_train, df_val, tokenizer):\n\n    train_dataset = DataSequence(df_train, tokenizer)\n    val_dataset = DataSequence(df_val, tokenizer)\n\n    train_dataloader = DataLoader(train_dataset, num_workers=4, batch_size=BATCH_SIZE, shuffle=True)\n    val_dataloader = DataLoader(val_dataset, num_workers=4, batch_size=BATCH_SIZE)\n\n    use_cuda = torch.cuda.is_available()\n    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n\n    optimizer = SGD(model.parameters(), lr=LEARNING_RATE)\n\n    if use_cuda:\n        model = model.cuda()\n\n    best_acc = 0\n    best_loss = 1000\n    train_metrics = []\n    val_metrics = []\n\n    for epoch_num in range(EPOCHS):\n\n        total_acc_train = 0\n        total_loss_train = 0\n        train_preds = []\n        train_labels = []\n        val_preds = []\n        val_labels = []\n\n        model.train()\n\n        for train_data, train_label in tqdm(train_dataloader):\n\n            train_label = train_label.to(device)\n            mask = train_data['attention_mask'].squeeze(1).to(device)\n            input_id = train_data['input_ids'].squeeze(1).to(device)\n            \n            optimizer.zero_grad()\n            loss, logits = model(input_id, mask, train_label)\n\n            for i in range(logits.shape[0]):\n\n                logits_clean = logits[i][train_label[i] != -100]\n                label_clean = train_label[i][train_label[i] != -100]\n\n                predictions = logits_clean.argmax(dim=1)\n                acc = (predictions == label_clean).float().mean()\n                train_labels.append(label_clean.to('cpu')[0])\n                train_preds.append(predictions.to('cpu')[0])\n                total_acc_train += acc\n                total_loss_train += loss.item()\n\n            loss.backward()\n            optimizer.step()\n            #break\n        trm = classification_report(train_labels, train_preds,labels=np.arange(0,len(list(ids_to_labels.values())),1), target_names=list(ids_to_labels.values()), output_dict=True)\n        train_metrics.append(trm)\n\n        model.eval()\n\n        total_acc_val = 0\n        total_loss_val = 0\n\n        for val_data, val_label in val_dataloader:\n\n            val_label = val_label.to(device)\n            mask = val_data['attention_mask'].squeeze(1).to(device)\n            input_id = val_data['input_ids'].squeeze(1).to(device)\n\n            loss, logits = model(input_id, mask, val_label)\n\n            for i in range(logits.shape[0]):\n\n                logits_clean = logits[i][val_label[i] != -100]\n                label_clean = val_label[i][val_label[i] != -100]\n\n                predictions = logits_clean.argmax(dim=1)\n                acc = (predictions == label_clean).float().mean()\n                val_labels.append(label_clean.to('cpu')[0])\n                val_preds.append(predictions.to('cpu')[0])\n                total_acc_val += acc\n                total_loss_val += loss.item()\n\n        val_accuracy = total_acc_val / len(df_val)\n        val_loss = total_loss_val / len(df_val)\n        vrm = classification_report(val_labels, val_preds,labels=np.arange(0,len(list(ids_to_labels.values())),1), target_names=list(ids_to_labels.values()), output_dict=True)\n        val_metrics.append(vrm)\n        \n        print(\n            f'Epochs: {epoch_num + 1} | Loss: {total_loss_train / len(df_train): .3f} | Accuracy: {total_acc_train / len(df_train): .3f} | Val_Loss: {total_loss_val / len(df_val): .3f} | Accuracy: {total_acc_val / len(df_val): .3f}')\n    return train_metrics, val_metrics\n","metadata":{"execution":{"iopub.status.busy":"2023-05-08T03:09:10.881117Z","iopub.execute_input":"2023-05-08T03:09:10.881457Z","iopub.status.idle":"2023-05-08T03:09:10.896184Z","shell.execute_reply.started":"2023-05-08T03:09:10.881430Z","shell.execute_reply":"2023-05-08T03:09:10.895283Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def evaluate(model, df_test, tokenizer):\n\n    test_dataset = DataSequence(df_test, tokenizer)\n\n    test_dataloader = DataLoader(test_dataset, num_workers=4, batch_size=1)\n\n    use_cuda = torch.cuda.is_available()\n    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n\n    if use_cuda:\n        model = model.cuda()\n\n    total_acc_test = 0.0\n    test_preds = []\n    test_labels = []\n\n    for test_data, test_label in test_dataloader:\n\n        test_label = test_label.to(device)\n        mask = test_data['attention_mask'].squeeze(1).to(device)\n\n        input_id = test_data['input_ids'].squeeze(1).to(device)\n\n        loss, logits = model(input_id, mask, test_label)\n\n        for i in range(logits.shape[0]):\n\n            logits_clean = logits[i][test_label[i] != -100]\n            label_clean = test_label[i][test_label[i] != -100]\n            test_labels.append(label_clean.to('cpu')[0])\n\n            predictions = logits_clean.argmax(dim=1)\n            acc = (predictions == label_clean).float().mean()\n            total_acc_test += acc\n            test_preds.append(predictions.to('cpu')[0])\n\n    val_accuracy = total_acc_test / len(df_test)\n    print(f'Test Accuracy: {total_acc_test / len(df_test): .3f}')\n    test_rep = classification_report(test_labels, test_preds, labels=np.arange(0,len(list(ids_to_labels.values())),1), target_names=list(ids_to_labels.values()), output_dict=True)\n    return test_rep","metadata":{"execution":{"iopub.status.busy":"2023-05-08T03:10:15.860282Z","iopub.execute_input":"2023-05-08T03:10:15.860637Z","iopub.status.idle":"2023-05-08T03:10:15.871228Z","shell.execute_reply.started":"2023-05-08T03:10:15.860610Z","shell.execute_reply":"2023-05-08T03:10:15.870207Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x=0","metadata":{"execution":{"iopub.status.busy":"2023-05-08T03:06:43.639130Z","iopub.status.idle":"2023-05-08T03:06:43.639583Z","shell.execute_reply.started":"2023-05-08T03:06:43.639356Z","shell.execute_reply":"2023-05-08T03:06:43.639378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"warnings.filterwarnings('ignore')\n\n# K-Fold Cross Validation.\n\nfrom sklearn.model_selection import KFold\n\nLEARNING_RATE = 5e-3\nEPOCHS = 5\nBATCH_SIZE = 2\nNUM_FOLDS = 5\n\n# Define the number of splits and random seed for reproducibility\nkf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=42)\n\ntrain_metrics_mlb = []\nval_metrics_mlb = []\ntest_metrics_mlb = []\n\nfor fold, (train_index, val_index) in enumerate(kf.split(train_df)):\n\n    print(f'Fold {fold+1}')\n\n    # Get train and validation data for this fold\n    df_train = train_df.iloc[train_index]\n    df_val = train_df.iloc[val_index]\n\n    # Initialize the model\n    model = MultilingualBert()\n\n    # Call the train_loop function for this fold\n    train_metrics, val_metrics = train_loop(model, df_train, df_val, tokenizer_mlb)\n    \n    # Evaluate over the testa dataset\n    test_metrics = evaluate(model, testa_df, tokenizer_mlb)\n\n    # Add the metrics for this fold to the lists\n    train_metrics_mlb.append(train_metrics)\n    val_metrics_mlb.append(val_metrics)\n    test_metrics_mlb.append(test_metrics)","metadata":{"execution":{"iopub.status.busy":"2023-05-08T03:10:21.178250Z","iopub.execute_input":"2023-05-08T03:10:21.178601Z","iopub.status.idle":"2023-05-08T06:17:09.812463Z","shell.execute_reply.started":"2023-05-08T03:10:21.178574Z","shell.execute_reply":"2023-05-08T06:17:09.811212Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Fold 1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/714M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e77614a906f94f3e9d5f4e8845d20dce"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n  0%|          | 0/3329 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3329/3329 [06:38<00:00,  8.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpochs: 1 | Loss:  0.225 | Accuracy:  0.941 | Val_Loss:  0.207 | Accuracy:  0.951\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/3329 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3329/3329 [06:37<00:00,  8.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpochs: 2 | Loss:  0.159 | Accuracy:  0.958 | Val_Loss:  0.159 | Accuracy:  0.960\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/3329 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3329/3329 [06:36<00:00,  8.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpochs: 3 | Loss:  0.130 | Accuracy:  0.964 | Val_Loss:  0.142 | Accuracy:  0.963\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/3329 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3329/3329 [06:37<00:00,  8.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpochs: 4 | Loss:  0.104 | Accuracy:  0.971 | Val_Loss:  0.117 | Accuracy:  0.967\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/3329 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stderr","text":"100%|█████████▉| 3328/3329 [06:37<00:00,  8.34it/s]","output_type":"stream"},{"name":"stdout","text":"To disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3329/3329 [06:38<00:00,  8.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpochs: 5 | Loss:  0.093 | Accuracy:  0.973 | Val_Loss:  0.125 | Accuracy:  0.966\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nTest Accuracy:  0.956\nFold 2\n","output_type":"stream"},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n  0%|          | 0/3329 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3329/3329 [06:38<00:00,  8.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpochs: 1 | Loss:  0.280 | Accuracy:  0.929 | Val_Loss:  0.202 | Accuracy:  0.947\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/3329 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3329/3329 [06:40<00:00,  8.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpochs: 2 | Loss:  0.161 | Accuracy:  0.958 | Val_Loss:  0.157 | Accuracy:  0.961\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/3329 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3329/3329 [06:40<00:00,  8.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpochs: 3 | Loss:  0.141 | Accuracy:  0.962 | Val_Loss:  0.161 | Accuracy:  0.960\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/3329 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stderr","text":"100%|█████████▉| 3328/3329 [06:40<00:00,  8.37it/s]","output_type":"stream"},{"name":"stdout","text":"To disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3329/3329 [06:40<00:00,  8.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpochs: 4 | Loss:  0.109 | Accuracy:  0.969 | Val_Loss:  0.275 | Accuracy:  0.948\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/3329 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stderr","text":"100%|█████████▉| 3328/3329 [06:40<00:00,  8.35it/s]","output_type":"stream"},{"name":"stdout","text":"To disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3329/3329 [06:40<00:00,  8.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpochs: 5 | Loss:  0.094 | Accuracy:  0.972 | Val_Loss:  0.121 | Accuracy:  0.968\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nTest Accuracy:  0.957\nFold 3\n","output_type":"stream"},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n  0%|          | 0/3329 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3329/3329 [06:38<00:00,  8.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpochs: 1 | Loss:  0.650 | Accuracy:  0.875 | Val_Loss:  0.656 | Accuracy:  0.878\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/3329 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3329/3329 [06:37<00:00,  8.34it/s]","output_type":"stream"},{"name":"stdout","text":"To disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3329/3329 [06:37<00:00,  8.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpochs: 2 | Loss:  0.647 | Accuracy:  0.876 | Val_Loss:  0.669 | Accuracy:  0.878\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/3329 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3329/3329 [06:38<00:00,  8.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpochs: 3 | Loss:  0.640 | Accuracy:  0.876 | Val_Loss:  0.662 | Accuracy:  0.878\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/3329 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3329/3329 [06:37<00:00,  8.40it/s]","output_type":"stream"},{"name":"stdout","text":"To disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3329/3329 [06:38<00:00,  8.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpochs: 4 | Loss:  0.644 | Accuracy:  0.876 | Val_Loss:  0.661 | Accuracy:  0.878\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/3329 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3329/3329 [06:37<00:00,  8.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpochs: 5 | Loss:  0.640 | Accuracy:  0.876 | Val_Loss:  0.667 | Accuracy:  0.878\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nTest Accuracy:  0.864\nFold 4\n","output_type":"stream"},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n  0%|          | 0/3329 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3329/3329 [06:37<00:00,  8.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpochs: 1 | Loss:  0.240 | Accuracy:  0.938 | Val_Loss:  0.165 | Accuracy:  0.959\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/3329 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3329/3329 [06:37<00:00,  8.38it/s]","output_type":"stream"},{"name":"stdout","text":"To disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3329/3329 [06:37<00:00,  8.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpochs: 2 | Loss:  0.171 | Accuracy:  0.955 | Val_Loss:  0.149 | Accuracy:  0.963\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/3329 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3329/3329 [06:36<00:00,  8.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpochs: 3 | Loss:  0.138 | Accuracy:  0.964 | Val_Loss:  0.138 | Accuracy:  0.964\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/3329 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3329/3329 [06:36<00:00,  8.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpochs: 4 | Loss:  0.117 | Accuracy:  0.967 | Val_Loss:  0.126 | Accuracy:  0.965\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/3329 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3329/3329 [06:36<00:00,  8.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpochs: 5 | Loss:  0.113 | Accuracy:  0.967 | Val_Loss:  0.114 | Accuracy:  0.969\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nTest Accuracy:  0.955\nFold 5\n","output_type":"stream"},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n  0%|          | 0/3329 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3329/3329 [06:36<00:00,  8.48it/s]","output_type":"stream"},{"name":"stdout","text":"To disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3329/3329 [06:36<00:00,  8.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpochs: 1 | Loss:  0.234 | Accuracy:  0.940 | Val_Loss:  0.182 | Accuracy:  0.956\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/3329 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3329/3329 [06:36<00:00,  8.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpochs: 2 | Loss:  0.161 | Accuracy:  0.959 | Val_Loss:  0.164 | Accuracy:  0.961\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/3329 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3329/3329 [06:36<00:00,  8.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpochs: 3 | Loss:  0.133 | Accuracy:  0.964 | Val_Loss:  0.136 | Accuracy:  0.965\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/3329 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3329/3329 [06:36<00:00,  8.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpochs: 4 | Loss:  0.110 | Accuracy:  0.968 | Val_Loss:  0.142 | Accuracy:  0.966\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/3329 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3329/3329 [06:36<00:00,  8.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpochs: 5 | Loss:  0.167 | Accuracy:  0.956 | Val_Loss:  0.149 | Accuracy:  0.962\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nTest Accuracy:  0.951\n","output_type":"stream"}]},{"cell_type":"code","source":"import pickle\nfilename = 'finalized_model6.sav'\npickle.dump(model, open(filename, 'wb'))","metadata":{"execution":{"iopub.status.busy":"2023-05-08T09:03:00.217493Z","iopub.execute_input":"2023-05-08T09:03:00.217814Z","iopub.status.idle":"2023-05-08T09:03:00.496422Z","shell.execute_reply.started":"2023-05-08T09:03:00.217787Z","shell.execute_reply":"2023-05-08T09:03:00.494484Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[1;32m      2\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinalized_model6.sav\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m pickle\u001b[38;5;241m.\u001b[39mdump(\u001b[43mmodel\u001b[49m, \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m))\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"],"ename":"NameError","evalue":"name 'model' is not defined","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n\nevaluate(model, df_test)","metadata":{"execution":{"iopub.status.busy":"2023-05-08T07:04:09.472788Z","iopub.execute_input":"2023-05-08T07:04:09.473674Z","iopub.status.idle":"2023-05-08T07:04:09.498364Z","shell.execute_reply.started":"2023-05-08T07:04:09.473631Z","shell.execute_reply":"2023-05-08T07:04:09.496934Z"},"trusted":true},"execution_count":21,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m evaluate(model, \u001b[43mdf_test\u001b[49m)\n","\u001b[0;31mNameError\u001b[0m: name 'df_test' is not defined"],"ename":"NameError","evalue":"name 'df_test' is not defined","output_type":"error"}]},{"cell_type":"code","source":"evaluate(model, testa_df)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-08T07:04:15.774231Z","iopub.execute_input":"2023-05-08T07:04:15.774583Z","iopub.status.idle":"2023-05-08T07:04:15.797438Z","shell.execute_reply.started":"2023-05-08T07:04:15.774548Z","shell.execute_reply":"2023-05-08T07:04:15.796178Z"},"trusted":true},"execution_count":22,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtesta_df\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mTypeError\u001b[0m: evaluate() missing 1 required positional argument: 'tokenizer'"],"ename":"TypeError","evalue":"evaluate() missing 1 required positional argument: 'tokenizer'","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# parse the classification reports for each epoch into dictionaries\nepoch_reports_train = train_metrics\nepoch_reports_val = val_metrics\n# extract the metrics of interest for each epoch\nprecision_train = [report['weighted avg']['precision'] for report in epoch_reports_train]\nrecall_train = [report['weighted avg']['recall'] for report in epoch_reports_train]\nf1_score_train = [report['weighted avg']['f1-score'] for report in epoch_reports_train]\nprecision_val = [report['weighted avg']['precision'] for report in epoch_reports_val]\nrecall_val = [report['weighted avg']['recall'] for report in epoch_reports_val]\nf1_score_val = [report['weighted avg']['f1-score'] for report in epoch_reports_val]\n\n\n# create line plots for each metric over the epochs\nepochs = range(1, len(epoch_reports_train) + 1)\n#plt.plot(epochs, precision_train, label='Precision (train)')\nplt.plot(epochs, recall_train, label='Recall (train)')\n#plt.plot(epochs, f1_score_train, label='F1-score (train)')\n#plt.plot(epochs, precision_val, label='Precision (val)')\nplt.plot(epochs, recall_val, label='Recall (val)')\n#plt.plot(epochs, f1_score_val, label='F1-score (val)')\nplt.xlabel('Epochs')\nplt.ylabel('Metric')\nplt.title('Performance over Epochs')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-08T07:05:22.805315Z","iopub.execute_input":"2023-05-08T07:05:22.805686Z","iopub.status.idle":"2023-05-08T07:05:23.092734Z","shell.execute_reply.started":"2023-05-08T07:05:22.805657Z","shell.execute_reply":"2023-05-08T07:05:23.091858Z"},"trusted":true},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAkgAAAHHCAYAAABEEKc/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAA9hAAAPYQGoP6dpAACLD0lEQVR4nOzdeVgVZfvA8e857MimsiuyieKKhkrulguKlpa5palYVqYtkpmaabvVm2aZqfnLJa1ccsk0LcUld82lNDcEFVwAUQEBWc/8/jhy9AgoIDAs9+e6zvXCzDMz98PYy80zz/2MRlEUBSGEEEIIYaBVOwAhhBBCiPJGEiQhhBBCiHtIgiSEEEIIcQ9JkIQQQggh7iEJkhBCCCHEPSRBEkIIIYS4hyRIQgghhBD3kARJCCGEEOIekiAJIYQQQtxDEiQhqoD//e9/+Pj4YGJiQrNmzdQORwi2b9+ORqPhl19+UTsUIfIlCZIQKli0aBEajcbwsbS0pF69eowZM4a4uLgSvdaff/7J+PHjadu2LQsXLuSTTz4p0fOL8ik3ASnos2zZMrVDFKJcM1U7ACGqsg8++ABvb2/S09PZtWsXc+bM4ffff+f48eNYW1uXyDW2bt2KVqvl+++/x9zcvETOKSqO1157jZYtW+bZ3rp1axWiEaLikARJCBX16NGDFi1aAPDCCy9Qs2ZNZsyYwa+//sqgQYMe6txpaWlYW1sTHx+PlZVViSVHiqKQnp6OlZVViZxPFF9qairVqlW7b5v27dvzzDPPlFFEQlQe8ohNiHLk8ccfB+DcuXOGbUuXLiUwMBArKytq1KjBwIEDiYmJMTquU6dONG7cmEOHDtGhQwesra2ZNGkSGo2GhQsXkpqaani0smjRIgCys7P58MMP8fX1xcLCAi8vLyZNmkRGRobRub28vOjVqxd//PEHLVq0wMrKinnz5hke4axYsYL333+fWrVqYWtryzPPPENSUhIZGRm88cYbODs7Y2NjQ2hoaJ5zL1y4kMcffxxnZ2csLCxo2LAhc+bMyfNzyY1h165dtGrVCktLS3x8fPjhhx/ytE1MTGTs2LF4eXlhYWFB7dq1GTp0KAkJCYY2GRkZTJ06lbp162JhYYGHhwfjx4/PE19BVq5cabgnjo6ODBkyhEuXLhn2f/HFF2g0Gi5cuJDn2IkTJ2Jubs6NGzcM2/bv30/37t2xt7fH2tqajh07snv3bqPj3nvvPTQaDSdOnODZZ5+levXqtGvXrlDxPohGo2HMmDH8+OOP1K9fH0tLSwIDA/nrr7/ytD1y5Ag9evTAzs4OGxsbOnfuzL59+/K0K8x9ANDpdHz88cfUrl0bS0tLOnfuzNmzZ43aRERE0LdvX1xdXbG0tKR27doMHDiQpKSkEum/EPmRESQhypHIyEgAatasCcDHH3/Mu+++S//+/XnhhRe4evUqs2bNokOHDhw5cgQHBwfDsdeuXaNHjx4MHDiQIUOG4OLiQosWLfjuu+84cOAA//d//wdAmzZtAP2I1eLFi3nmmWd488032b9/P9OmTePkyZOsWbPGKK7Tp08zaNAgXnrpJUaOHEn9+vUN+6ZNm4aVlRUTJkzg7NmzzJo1CzMzM7RaLTdu3OC9995j3759LFq0CG9vb6ZMmWI4ds6cOTRq1Ignn3wSU1NTfvvtN1555RV0Oh2jR482iuHs2bM888wzPP/88wwbNowFCxYwfPhwAgMDadSoEQApKSm0b9+ekydPMmLECB555BESEhJYt24dFy9exNHREZ1Ox5NPPsmuXbt48cUXadCgAceOHePLL7/kzJkzrF279r73aNGiRYSGhtKyZUumTZtGXFwcX331Fbt37zbck/79+zN+/HhWrFjBW2+9ZXT8ihUr6NatG9WrVwf0j0B79OhBYGAgU6dORavVGhLHnTt30qpVK6Pj+/Xrh5+fH5988gmKotw3VoCbN2/mSUpA/29Mo9EYvt+xYwfLly/ntddew8LCgm+//Zbu3btz4MABGjduDMB///1H+/btsbOzY/z48ZiZmTFv3jw6derEjh07CAoKKvR9yPXpp5+i1WoZN24cSUlJfP755wwePJj9+/cDkJmZSXBwMBkZGbz66qu4urpy6dIl1q9fT2JiIvb29g/8GQhRLIoQoswtXLhQAZQtW7YoV69eVWJiYpRly5YpNWvWVKysrJSLFy8q58+fV0xMTJSPP/7Y6Nhjx44ppqamRts7duyoAMrcuXPzXGvYsGFKtWrVjLYdPXpUAZQXXnjBaPu4ceMUQNm6dathm6enpwIomzZtMmq7bds2BVAaN26sZGZmGrYPGjRI0Wg0So8ePYzat27dWvH09DTalpaWlife4OBgxcfHx2hbbgx//fWXYVt8fLxiYWGhvPnmm4ZtU6ZMUQBl9erVec6r0+kURVGUJUuWKFqtVtm5c6fR/rlz5yqAsnv37jzH5srMzFScnZ2Vxo0bK7du3TJsX79+vQIoU6ZMMepvYGCg0fEHDhxQAOWHH34wxOTn56cEBwcb4sv9uXh7eytdu3Y1bJs6daoCKIMGDSowvrvl3p+CPleuXDG0zd32999/G7ZduHBBsbS0VJ566inDtj59+ijm5uZKZGSkYdvly5cVW1tbpUOHDoZthbkPufE1aNBAycjIMOz/6quvFEA5duyYoiiKcuTIEQVQVq5cWah+C1FS5BGbECrq0qULTk5OeHh4MHDgQGxsbFizZg21atVi9erV6HQ6+vfvT0JCguHj6uqKn58f27ZtMzqXhYUFoaGhhbru77//DkBYWJjR9jfffBOADRs2GG339vYmODg433MNHToUMzMzw/dBQUEoisKIESOM2gUFBRETE0N2drZh293zmJKSkkhISKBjx45ERUXleXzSsGFD2rdvb/jeycmJ+vXrExUVZdi2atUqAgICeOqpp/LEmTtasnLlSho0aIC/v7/RzzX38ea9P9e7/f3338THx/PKK69gaWlp2N6zZ0/8/f2Nfm4DBgzg0KFDhlFBgOXLl2NhYUHv3r0BOHr0KBERETz77LNcu3bNEEtqaiqdO3fmr7/+QqfTGcXw8ssvFxhffqZMmcLmzZvzfGrUqGHUrnXr1gQGBhq+r1OnDr179+aPP/4gJyeHnJwc/vzzT/r06YOPj4+hnZubG88++yy7du0iOTkZKNx9yBUaGmo0Py73Hufe19wRoj/++IO0tLQi9V2IhyGP2IRQ0ezZs6lXrx6mpqa4uLhQv359tFr93y0REREoioKfn1++x96dlADUqlWr0BOxL1y4gFarpW7dukbbXV1dcXBwyDN3xtvbu8Bz1alTx+j73F9oHh4eebbrdDqSkpIMjxB3797N1KlT2bt3b55ffklJSUaPT+69DkD16tWN5vJERkbSt2/fAmMF/c/15MmTODk55bs/Pj6+wGNzfy53P2LM5e/vz65duwzf9+vXj7CwMJYvX86kSZNQFIWVK1ca5u/kxgIwbNiwAq+ZlJRkeBwH978X+WnSpAldunR5YLv8/p3Vq1ePtLQ0rl69Cugn/ufX9wYNGqDT6YiJiaFRo0aFug+57r2vuX3Nva/e3t6EhYUxY8YMfvzxR9q3b8+TTz7JkCFD5PGaKFWSIAmholatWhmq2O6l0+nQaDRs3LgRExOTPPttbGyMvi9OVdm9f80X5H7nzi+2+21Xbs+biYyMpHPnzvj7+zNjxgw8PDwwNzfn999/58svv8wzcvKg8xWWTqejSZMmzJgxI9/99yZ2xeXu7k779u1ZsWIFkyZNYt++fURHR/PZZ58ZxQL6hTwLWsCzJO5zeVaY+zp9+nSGDx/Or7/+yp9//slrr73GtGnT2LdvH7Vr1y6rUEUVIwmSEOWUr68viqLg7e1NvXr1SvTcnp6e6HQ6IiIiaNCggWF7XFwciYmJeHp6luj18vPbb7+RkZHBunXrjEYR7veI60F8fX05fvz4A9v8888/dO7cudAJYq7cn8vp06cNj+RynT59Os/PbcCAAbzyyiucPn2a5cuXY21tzRNPPGEUC4CdnV2hRnlKU+5o1t3OnDmDtbW1YbTN2tqa06dP52l36tQptFqtIbkszH0oqiZNmtCkSRMmT57Mnj17aNu2LXPnzuWjjz4q0esIkUvmIAlRTj399NOYmJjw/vvv5xklURSFa9euFfvcISEhAMycOdNoe+6oSs+ePYt97sLKHTm4u29JSUksXLiw2Ofs27cv//zzT54qvLuv079/fy5dusT8+fPztLl16xapqakFnr9FixY4Ozszd+5coyUBNm7cyMmTJ/P83Pr27YuJiQk///wzK1eupFevXkbrFgUGBuLr68sXX3xBSkpKnuvlPtoqC3v37uXw4cOG72NiYvj111/p1q0bJiYmmJiY0K1bN3799VfOnz9vaBcXF8dPP/1Eu3btDI8OC3MfCis5Odlo3hrokyWtVlvoZRmEKA4ZQRKinPL19eWjjz5i4sSJnD9/nj59+mBra8u5c+dYs2YNL774IuPGjSvWuQMCAhg2bBjfffcdiYmJdOzYkQMHDrB48WL69OnDY489VsK9yatbt26Ym5vzxBNP8NJLL5GSksL8+fNxdnbmypUrxTrnW2+9xS+//EK/fv0YMWIEgYGBXL9+nXXr1jF37lwCAgJ47rnnWLFiBS+//DLbtm2jbdu25OTkcOrUKVasWGFY7yk/ZmZmfPbZZ4SGhtKxY0cGDRpkKPP38vJi7NixRu2dnZ157LHHmDFjBjdv3mTAgAFG+7VaLf/3f/9Hjx49aNSoEaGhodSqVYtLly6xbds27Ozs+O2334r1s8i1c+dO0tPT82xv2rQpTZs2NXzfuHFjgoODjcr8Ad5//31Dm48++ojNmzfTrl07XnnlFUxNTZk3bx4ZGRl8/vnnhnaFuQ+FtXXrVsaMGUO/fv2oV68e2dnZLFmyBBMTk0LPcxKiWNQpnhOiasst8z948OAD265atUpp166dUq1aNaVatWqKv7+/Mnr0aOX06dOGNh07dlQaNWqU7/H5lfkriqJkZWUp77//vuLt7a2YmZkpHh4eysSJE5X09HSjdp6enkrPnj3zHJ9bpn1v+XVBfcstU7969aph27p165SmTZsqlpaWipeXl/LZZ58pCxYsUADl3LlzD4yhY8eOSseOHY22Xbt2TRkzZoxSq1YtxdzcXKldu7YybNgwJSEhwdAmMzNT+eyzz5RGjRopFhYWSvXq1ZXAwEDl/fffV5KSkvL+EO+xfPlypXnz5oqFhYVSo0YNZfDgwcrFixfzbTt//nwFUGxtbY2WBrjbkSNHlKefflqpWbOmYmFhoXh6eir9+/dXwsPD7/vzu58HlflPnTrV0BZQRo8erSxdulTx8/NTLCwslObNmyvbtm3Lc97Dhw8rwcHBio2NjWJtba089thjyp49e/K0e9B9KOjfz7lz5xRAWbhwoaIoihIVFaWMGDFC8fX1VSwtLZUaNWoojz32mLJly5ZC/RyEKC6NohRxvFMIIUSlotFoGD16NN98843aoQhRbsgcJCGEEEKIe0iCJIQQQghxD0mQhBBCCCHuIVVsQghRxclUVCHykhEkIYQQQoh7SIIkhBBCCHEPecRWTDqdjsuXL2Nra1vk1xUIIYQQQh2KonDz5k3c3d0NLwfPjyRIxXT58uUSe6mlEEIIIcpWTEzMfV92LAlSMdna2gL6H3Du+4eEEEIIUb4lJyfj4eFh+D1eEEmQiin3sZqdnZ0kSEIIIUQF86DpMTJJWwghhBDiHpIgCSGEEELcQxIkIYQQQoh7yBykUpaTk0NWVpbaYYhyyMzMDBMTE7XDEEIIkQ9JkEqJoijExsaSmJiodiiiHHNwcMDV1VXW0hJCiHJGEqRSkpscOTs7Y21tLb8AhRFFUUhLSyM+Ph4ANzc3lSMSQghxN9UTpNmzZ/O///2P2NhYAgICmDVrFq1atcq3bVZWFtOmTWPx4sVcunSJ+vXr89lnn9G9e3dDm5ycHN577z2WLl1KbGws7u7uDB8+nMmTJxuSFEVRmDp1KvPnzycxMZG2bdsyZ84c/Pz8SqRPOTk5huSoZs2aJXJOUflYWVkBEB8fj7OzszxuE0KIckTVSdrLly8nLCyMqVOncvjwYQICAggODjb8VX2vyZMnM2/ePGbNmsWJEyd4+eWXeeqppzhy5IihzWeffcacOXP45ptvOHnyJJ999hmff/45s2bNMrT5/PPP+frrr5k7dy779++nWrVqBAcHk56eXiL9yp1zZG1tXSLnE5VX7r8RmacmhBDli0ZRFEWtiwcFBdGyZUu++eYbQP9+Mw8PD1599VUmTJiQp727uzvvvPMOo0ePNmzr27cvVlZWLF26FIBevXrh4uLC999/n28bRVFwd3fnzTffZNy4cQAkJSXh4uLCokWLGDhwYKFiT05Oxt7enqSkpDwLRaanp3Pu3Dm8vb2xtLQs2g9FVCnyb0UIIcrW/X5/3021EaTMzEwOHTpEly5d7gSj1dKlSxf27t2b7zEZGRl5folYWVmxa9cuw/dt2rQhPDycM2fOAPDPP/+wa9cuevToAcC5c+eIjY01uq69vT1BQUEFXjf32snJyUYfIYQQQlROqiVICQkJ5OTk4OLiYrTdxcWF2NjYfI8JDg5mxowZREREoNPp2Lx5M6tXr+bKlSuGNhMmTGDgwIH4+/tjZmZG8+bNeeONNxg8eDCA4dxFuS7AtGnTsLe3N3zkRbWlR6PRsHbtWgDOnz+PRqPh6NGj9z3m9OnTuLq6cvPmzVKJ6b333qNZs2ZFOubRRx9l1apVpRKPEEKI0lWhFor86quv8PPzw9/fH3Nzc8aMGUNoaCha7Z1urFixgh9//JGffvqJw4cPs3jxYr744gsWL178UNeeOHEiSUlJhk9MTMzDdqfcGT58OBqNBo1Gg5mZGd7e3owfP77E5maVpokTJ/Lqq68aXj64aNEiHBwcSuz848aNIzw8vEjHTJ48mQkTJqDT6UosDiGEEGVDtQTJ0dERExMT4uLijLbHxcXh6uqa7zFOTk6sXbuW1NRULly4wKlTp7CxscHHx8fQ5q233jKMIjVp0oTnnnuOsWPHMm3aNADDuYtyXQALCwvDi2kr8wtqu3fvzpUrV4iKiuLLL79k3rx5TJ06Ve2w7is6Opr169czfPjwIh+bmZlZqHY2NjZFrkjs0aMHN2/eZOPGjUWOSwjxkNKTQL0ptqISUC1BMjc3JzAw0Oivcp1OR3h4OK1bt77vsZaWltSqVYvs7GxWrVpF7969DfvS0tKMRpQATExMDH/Fe3t74+rqanTd5ORk9u/f/8DrVgUWFha4urri4eFBnz596NKlC5s3bzbs1+l0TJs2DW9vb6ysrAgICOCXX34xOsd///1Hr169sLOzw9bWlvbt2xMZGQnAwYMH6dq1K46Ojtjb29OxY0cOHz78UDGvWLGCgIAAatWqBcD27dsJDQ0lKSnJMCL23nvvAeDl5cWHH37I0KFDsbOz48UXXwTg7bffpl69elhbW+Pj48O7775rVFl27yO24cOH06dPH7744gvc3NyoWbMmo0ePNjrGxMSEkJAQli1b9lD9E0IUgqLAlX9h2ycwpy18WgfWvgIygiuKSdV1kMLCwhg2bBgtWrSgVatWzJw5k9TUVEJDQwEYOnQotWrVMoz+7N+/n0uXLtGsWTMuXbrEe++9h06nY/z48YZzPvHEE3z88cfUqVOHRo0aceTIEWbMmMGIESMA/fyWN954g48++gg/Pz+8vb159913cXd3p0+fPqXST0VRuJWVUyrnfhArM5NiL1J5/Phx9uzZg6enp2HbtGnTWLp0KXPnzsXPz4+//vqLIUOG4OTkRMeOHbl06RIdOnSgU6dObN26FTs7O3bv3k12djYAN2/eZNiwYcyaNQtFUZg+fTohISFEREQYHo8V1c6dO2nRooXh+zZt2jBz5kymTJnC6dOnAf0IUK4vvviCKVOmGI2M2drasmjRItzd3Tl27BgjR47E1tbW6N/WvbZt24abmxvbtm3j7NmzDBgwgGbNmjFy5EhDm1atWvHpp58Wq19CiAfIyYaYfXByPZzaAEnRxvv/+QmqOUK3D9WJT1RoqiZIAwYM4OrVq0yZMoXY2FiaNWvGpk2bDBOoo6OjjUaD0tPTmTx5MlFRUdjY2BASEsKSJUuM5prMmjWLd999l1deeYX4+Hjc3d156aWXmDJliqHN+PHjSU1N5cUXXyQxMZF27dqxadOmUiuzvpWVQ8Mpf5TKuR/kxAfBWJsX/javX78eGxsbsrOzycjIQKvVGpZhyMjI4JNPPmHLli2G0TYfHx927drFvHnz6NixI7Nnz8be3p5ly5ZhZmYGQL169Qznf/zxx42u99133+Hg4MCOHTvo1atXsfp44cIFowTJ3Nwce3t7NBpNvo9NH3/8cd58802jbZMnTzZ87eXlxbhx41i2bNl9E6Tq1avzzTffYGJigr+/Pz179iQ8PNwoQXJ3dycmJgadTpdnZFMIUQxZtyByG5xaD6c3wq3rd/aZWkHdzuDfC7LSYEMY7Pka7Nzh0VHqxSwqJNVX0h4zZgxjxozJd9/27duNvu/YsSMnTpy47/lsbW2ZOXMmM2fOLLCNRqPhgw8+4IMPPihquJXeY489xpw5c0hNTeXLL7/E1NSUvn37AnD27FnS0tLo2rWr0TGZmZk0b94cgKNHj9K+fXtDcnSvuLg4Jk+ezPbt24mPjycnJ4e0tDSio6PzbV8Yt27dKlJye3cylWv58uV8/fXXREZGkpKSQnZ29gPnmTVq1Mho9Ws3NzeOHTtm1MbKygqdTkdGRoZh5WwhRBGlXYeIP+HkbxC5VZ/85LKqDvVDwL8n+DwG5nct0JueBOHvw6aJYOsKjZ4q+9hFhaV6glQVWJmZcOKDYNWuXRTVqlWjbt26ACxYsICAgAC+//57nn/+eVJSUgDYsGGDYb5PLgsLC/31HpAEDBs2jGvXrvHVV1/h6emJhYUFrVu3LvRk6fw4Ojpy48aNQrevVq2a0fd79+5l8ODBvP/++wQHBxtGwKZPn37f89ybBGo0mjwVa9evX6datWqSHAlRVEkX4dTvcOo3OL8blLumKdh76EeJ/HtCndZgUsCvsnZjIfkyHJwPq1+Eak7g1a5s4hcVniRIZUCj0RTpMVd5odVqmTRpEmFhYTz77LM0bNgQCwsLoqOj6dixY77HNG3alMWLF5OVlZXvKNLu3bv59ttvCQkJASAmJoaEhISHirN58+Z5RhbNzc3JySncvK/ceVbvvPOOYduFCxceKqZcx48fN4yuCSHuQ1Hg6in9o7OT6+HKUeP9zo2gwe2kyLUpFGZupUYDPT6DlFj96NPPz8KITeDSsFS6ICoXmRQh7qtfv36YmJgwe/ZsbG1tGTduHGPHjmXx4sVERkZy+PBhZs2aZVhnasyYMSQnJzNw4ED+/vtvIiIiWLJkiWGytJ+fH0uWLOHkyZPs37+fwYMHP/ToSnBwMHv37jVKiLy8vEhJSSE8PJyEhATS0tIKPN7Pz4/o6GiWLVtGZGQkX3/9NWvWrHmomHLt3LmTbt26lci5hKh0dDqI3g9/vguzAuHbR2HrR7eTI41+dKjbx/DaEXhlDzw2CdwCCpcc5dKawNPz9efKSIKlffWjU0I8gCRI4r5MTU0ZM2YMn3/+OampqXz44Ye8++67TJs2jQYNGtC9e3c2bNiAt7c3ADVr1mTr1q2kpKTQsWNHAgMDmT9/vmE06fvvv+fGjRs88sgjPPfcc7z22ms4Ozs/VIw9evTA1NSULVu2GLa1adOGl19+mQEDBuDk5MTnn39e4PFPPvkkY8eOZcyYMTRr1ow9e/bw7rvvPlRMAJcuXWLPnj2GqkwhBJCdARGb4bfXYXp9WNBNP5H6eiSYmINfMDzxNYyL0I/2tBkDNXwefN77MbOCQT+Dkz/cvAxLn4FbhX8sL6omVV9WW5HJy2rLl9mzZ7Nu3Tr++EOdasH8vP3229y4cYPvvvuuwDbyb0VUCenJ+knWpzbok6PMu14JZGEP9brpH53V7QIWxVvuo1ASY+D7rnDzCni2hSGrwUz+u6tqCvuy2oo3MUaIfLz00kskJiZy8+bNYq+nVNKcnZ0JCwtTOwwh1HEzDk7/rp9TFLUDdHcWUcXGVZ8Q+fcEr/Zgal42MTl4wJBVsKA7XNgNa16EZxaBLMEh8iEjSMUkI0iiJMi/FVGpXIu8M8n64kHgrl8vNf1uT7LuBe6PqJuUnPtLPxcpJxOCXobunxZtXpOo0GQESQghROlSFLh8RP/o7NR6fRXa3Wq1uD1S1Auc6uV/DjV4d4Cn5sIvI2D/XP1Ckm1fVzsqUc5IgiSEEKLwcrL0j6dObdB/ki/d2ac11T8ya9BLv3ijnbt6cT5I475wMxb+mASbp+gf+wUMUDsqUY5IgiSEEOL+MlPhbLg+ITqzCdIT7+wzqwZ+XcD/CfDrClYOakVZdK1H6xeS3PsN/PoK2DiB7+MPPk5UCZIgCSGEyCv1GpzZqE+KIrdCdvqdfdaOUL8HNHgCvDtW7Eqwrh/qq9qOr4Llz0Ho7/q1lkSVJwmSEEIIvRsX7jw6i94Dyl2vznHw1CdE/r3Ao5V+AcbKQKuFPnMgJR7O74Qf+8Hzf0J1L7UjEyqTBEkIIaoqRYG4//QTrE+th1jjly3j2lSfEDXoBc4NK2+ll6kFDPwRFoZA3HF9hduIP6FaTbUjEyqSBEkIIaoSXQ7E7NeX4p9aD4l3vXdQo9UvoJi7RpFDHfXiLGuW9jD4F/1CktfOws8DYeivYG6tdmRCJbI6lih3NBoNa9euBeD8+fNoNBqOHj1632NOnz6Nq6srN2/evG+7onjvvfdo1qyZ4fsJEybw6quvltj5hSgzWelwehP8Ohq+qAcLe8C+2frkyNQS6veE3t/CuLMwfD08OqpqJUe57Nz0C0laOsDFA7DqecjJVjsqoRJJkITB8OHD0Wg0aDQazMzM8Pb2Zvz48aSnpz/4YJVNnDiRV199tVRX0R43bhyLFy8mKiqq1K4hRIm5lQj/roAVQ+FzH/h5ABxZCmkJ+gQgYBAMWArjo2DQT9B8sDxSAnCqD88u1yeOp3+H39/UP4oUVY48YhNGunfvzsKFC8nKyuLQoUMMGzYMjUbDZ599pnZoBYqOjmb9+vXMmjWrVK/j6OhIcHAwc+bM4X//+1+pXkuIYkm+fGeS9fmdoLtr9MOu9p1HZ55twMRMvTjLuzqPQt//0yeXhxbpf3Yd31I7KlHGZARJGLGwsMDV1RUPDw/69OlDly5d2Lx5s2G/Tqdj2rRpeHt7Y2VlRUBAAL/88ovROf777z969eqFnZ0dtra2tG/fnsjISAAOHjxI165dcXR0xN7eno4dO3L48OGHinnFihUEBARQq1YtQL+MvJWVFRs3bjRqt2bNGmxtbUlLSwP0L5OtV68e1tbW+Pj48O6775KVlZXn/Hd74oknWLZs2UPFK0SJunoGdk6H+Y/DjAbw+ziI2qZPjpwaQIe34MXtMPY4hHwOPh0lOSqMBk9AyO0/hLZ9BIeXqBuPKHMyglQWFAWy0tS5tpl1sStPjh8/zp49e/D09DRsmzZtGkuXLmXu3Ln4+fnx119/MWTIEJycnOjYsSOXLl2iQ4cOdOrUia1bt2JnZ8fu3bvJztb/JXvz5k2GDRvGrFmzUBSF6dOnExISQkRERLEfj+3cuZMWLVoYvrezs6NXr1789NNP9OjRw7D9xx9/pE+fPlhb6ydd2trasmjRItzd3Tl27BgjR47E1taW8ePHF3itVq1acfHiRc6fP4+Xl1ex4hXioeh0cOnQ7cqzDXAt4q6dGn0Jfu7rPWr6qhZmpdDyBf2o3M7p8NvrYOMC9bqpHZUoI5IglYWsNPhEpSX3J10G82qFbr5+/XpsbGzIzs4mIyMDrVbLN998A0BGRgaffPIJW7ZsoXXr1gD4+Piwa9cu5s2bR8eOHZk9ezb29vYsW7YMMzP9X6n16t15B9PjjxuvUvvdd9/h4ODAjh076NWrV7G6eOHCBaMECWDw4ME899xzpKWlYW1tTXJyMhs2bGDNmjWGNpMnTzZ87eXlxbhx41i2bNl9EyR3d3fDNSVBEmUmO1P/yOzUejj1O6TE3tlnYq5frNG/p/71HrYu6sVZGT3+LiRfgX9+gpXDYNh6qB2odlSiDEiCJIw89thjzJkzh9TUVL788ktMTU3p27cvAGfPniUtLY2uXbsaHZOZmUnz5s0BOHr0KO3btzckR/eKi4tj8uTJbN++nfj4eHJyckhLSyM6OrrYMd+6dQtLS+OVfENCQjAzM2PdunUMHDiQVatWYWdnR5cuXQxtli9fztdff01kZCQpKSlkZ2ff983OAFZWVgCGx3RClJqMm3B2i74cP+JPyEi+s8/cVj+S4d8T6nYFy/v/uxUPQaOBJ7+GlDiIDIef+sHzm2V0rgqQBKksmFnrR3LUunYRVKtWjbp16wKwYMECAgIC+P7773n++edJSUkBYMOGDYb5PrksLCyAOwlEQYYNG8a1a9f46quv8PT0xMLCgtatW5OZmVmkOO/m6OjIjRs3jLaZm5vzzDPP8NNPPzFw4EB++uknBgwYgKmp/p/83r17GTx4MO+//z7BwcGGUa/p06ff91rXr18HwMnJqdjxClGglHg4vVE/UhS1HXLu+u/CxkU/QuTfC7zb6xc3FGXDxAz6/wCLesKVo7D0aX2SZOOsdmSiFEmCVBY0miI95iovtFotkyZNIiwsjGeffZaGDRtiYWFBdHQ0HTt2zPeYpk2bsnjxYrKysvIdRdq9ezfffvstISEhAMTExJCQkPBQcTZv3pwTJ07k2T548GC6du3Kf//9x9atW/noo48M+3LnVr3zzjuGbRcuXMhzjnsdP34cMzMzGjVq9FAxC2FwPequ13vsA+4qKa/hq1/F2r8X1Gqhfy2GUIeFDQxeqV9I8sZ5+Km//nGbhY3akYlSIv+1ifvq168fJiYmzJ49G1tbW8aNG8fYsWNZvHgxkZGRHD58mFmzZrF48WIAxowZQ3JyMgMHDuTvv/8mIiKCJUuWcPr0aQD8/PxYsmQJJ0+eZP/+/QwePPiBo04PEhwczN69e8nJyTHa3qFDB1xdXRk8eDDe3t4EBQUZ9vn5+REdHc2yZcuIjIzk66+/NpqfVJCdO3fSvn37h45ZVGGKApePwtaP4dvW8HVz+HMyRO8FFHBvrp/38sp+ePUQdP3g9rvP5P+uVWfjDENWg3VNuHxEPycp5/6Vr6Likv/ixH2ZmpoyZswYPv/8c1JTU/nwww959913mTZtGg0aNKB79+5s2LABb29vAGrWrMnWrVtJSUmhY8eOBAYGMn/+fMNo0vfff8+NGzd45JFHeO6553jttddwdn64YeoePXpgamrKli1bjLZrNBoGDRrEP//8w+DBg432Pfnkk4wdO5YxY8bQrFkz9uzZw7vvvvvAay1btoyRI0c+VLyiCsrJhnN/wca3YWYT+K4j/PU5xJ8AjYl+knXIFzD2P31Jfodx4Oxfed99VpHV9IVnV+qnL5zdoq9uk4UkKyWNosidLY7k5GTs7e1JSkrKM7E3PT2dc+fO4e3tnWfysCgds2fPZt26dfzxxx+ldo2NGzfy5ptv8u+//xrmMj0s+bdSiWWmQeRW/aOzMxvh1l3z5MysoW5n8H9CP9naqrp6cYriOfMH/DwIlBxoPw46P/gPLFE+3O/3991kDpKoFF566SUSExO5efNmqb1uJDU1lYULF5ZYciQqobTr+l+cp9bD2XDIvnVnn1UN/STrBr3ApxOYyWPaCq1eMDwxE9a9Cju/0L/HreULakclSpD8P72oFExNTY0mXJeGZ555plTPLyqoxJjbk6zXw4U9+hGFXA519BOs/XuBRxCYyP/lViqPDNWvkbT9E/j9LbBx1SfAolKQ/1qFEKIoFAXiT95Oin6DK/8Y73dpol+fqEEvcGks84gqu47jIfkSHF4Mq56Hob/q3+UmKjxJkIQQ4kF0OXDxoH6U6OR6uHHuzj6NFuq0vrOSdQ1v9eIUZU+jgZ4z9GtYndkIPw2A5/8Ep/pqRyYekiRIpUjmv4sHkX8j5Vh2BkTt0CdFp3+H1Kt39plYgO/jt5OiHlDNUb04hfpMTOGZBfDDk/pEemlf/UKSdm5qRyYeQrko8589ezZeXl5YWloSFBTEgQMHCmyblZXFBx98gK+vL5aWlgQEBLBp0yajNl5eXmg0mjyf0aNHG9p06tQpz/6XX365RPqTW9Iur6MQD5L7b6SgV7OIMpadqV/J+pcR8LmP/rUShxfrkyNLe2g6QL+i8vgoeHYZPPKcJEdCz9waBi2HmnUhKQZ+fAbSk9SOSjwE1UeQli9fTlhYGHPnziUoKIiZM2cSHBzM6dOn810fZ/LkySxdupT58+fj7+/PH3/8wVNPPcWePXsM7wM7ePCg0aKBx48fp2vXrvTr18/oXCNHjuSDDz4wfJ/7lveHZWJigoODA/Hx8YbzamQegriLoiikpaURHx+Pg4MDJiYmaodUdSmK/q/+f5fD8dVw6/qdfbbu+lEi/57g1U7/ygkhClKtJgxZBf/XFeKOw/IhMHgVmJqrHZkoBtXXQQoKCqJly5aGN8brdDo8PDx49dVXmTBhQp727u7uvPPOO0ajQX379sXKyoqlS5fme4033niD9evXExERYUhUOnXqRLNmzZg5c2ax4n7QOgqKohAbG0tiYmKxzi+qBgcHB1xdXSWBVkPCWTi2Qp8Y3Th/Z7uNCzR+Bhr31a9qLStYi6K68g8sDIHMFP2/pafny7+jcqRCrIOUmZnJoUOHmDhxomGbVqulS5cu7N27N99jMjIy8iyoZ2Vlxa5duwq8xtKlSwkLC8vzS+jHH39k6dKluLq68sQTT/Duu+8WOIqUkZFBRkaG4fvk5OR82+XSaDS4ubnh7OxMVpYsRS/yMjMzk5GjspZyFY6v0idFlw/f2W5WDRo+CU366Ve1lnJ88TDcAmDAEvixHxz/RT8XqdtHDz5OlCuq/r9AQkICOTk5uLi4GG13cXHh1KlT+R4THBzMjBkz6NChA76+voSHh7N69eo87+HKtXbtWhITExk+fLjR9meffRZPT0/c3d35999/efvttzl9+jSrV6/O9zzTpk3j/fffL3IfTUxM5JegEGrKTIVTv+uTositd9Yp0pjoV7NuOkA/0boCvlBalGO+j0Pv2bDmJdgzS/+4tvUrakcliqDC/Zn01VdfMXLkSPz9/dFoNPj6+hIaGsqCBQvybf/999/To0cP3N3djba/+OKLhq+bNGmCm5sbnTt3JjIyEl9f3zznmThxImFhYYbvk5OT8fDwKKFeCSFKVE42nNsO/67Ql+Vnpd7ZV6sFNO0PjZ4GGyfVQhRVQMBAuHkFtrwHf0wCW1do/LTaUYlCUjVBcnR0xMTEhLi4OKPtcXFxuLq65nuMk5MTa9euJT09nWvXruHu7s6ECRPw8fHJ0/bChQts2bKlwFGhu+W+6f3s2bP5JkgWFhZYWFgUpltCCDUoClw5qk+Kjv0CqfF39lX31o8UNe2vf9moEGWl7Rv61bYPzNOPJlVzAu/2akclCkHVBMnc3JzAwEDCw8Pp06cPoJ+kHR4ezpgxY+57rKWlJbVq1SIrK4tVq1bRv3//PG0WLlyIs7MzPXv2fGAsR48eBcDNTdatEKJCuXEe/l2pn3CdcObOduua+lGipgOgdotCr2itKArR19O4npqJiVaDVqP/mGg1mGgxfH33/2q1YJL7vVZz52uNBq0GTLQamYhfVWk00H2afiTp5DpYNhhGbASXRmpHJh5A9UdsYWFhDBs2jBYtWtCqVStmzpxJamoqoaGhAAwdOpRatWoxbdo0APbv38+lS5do1qwZly5d4r333kOn0zF+/Hij8+p0OhYuXMiwYcPyvFw0MjKSn376iZCQEGrWrMm///7L2LFj6dChA02bNi2bjgshii/tOvy3Rj9aFLPvznZTS31JftMB+jkghSzLv56aye6zCeyKSGDX2QQuJd568EFFpNHokyjjBArD90bbtXfaajV37dcan0OrvZOAGZK4e86lub3/3uNyz6UxJH+558jvGsbJoXGCWND2vH00ivP2+e5tf28SeieO/JPQ3J9ruU5CtSb6SrYlCRC9B5Y+Ay9sBvvaakcm7kP1BGnAgAFcvXqVKVOmEBsbS7Nmzdi0aZNh4nZ0dDTau8oj09PTmTx5MlFRUdjY2BASEsKSJUtwcHAwOu+WLVuIjo5mxIgRea5pbm7Oli1bDMmYh4cHffv2ZfLkyaXaVyHEQ8i6BWc26UeLIv4EXW51qAZ8OuqTIv9eYFlw2W6u9Kwc/j5/g51nr7IrIoH/LhtXpZqbaHG2s0CnU8hRFHJ0oFMUcnQKOkUxbNfpuL3/waulKApkKwoUoq0onruTUAsTLW91r8/Q1l5qh6VnZgmDfoIF3eHqKf1q2yM2gVV1tSMTBVB9HaSKqrDrKAghHoJOBxd26SvQTqyDjLsSGdem+qSocd8HvtJBp1M4cSVZP0p0NoED566Tka0zauPvakt7P0fa+TnRyqsGVuZFqz41JE33JE53kikFnYLh65y7tue2VRSMt9+ViOkU4+2624nbnXPnv92Q1N2T6OUYHVPQ9jt9uTvOO231jyTv3W44xug4jH4WRj+rwvwsFP22orA2N2H7uE4421k+uHFZSbqoX0jy5mWo0waeW6NPnkSZqRDrIAkhRL5ij99e2XqV/k3puew99GsVNe0Pzg3ue4rLibfYFZHAzrMJ7DmbwLXUTKP9LnYWtKvrRHs/R9rWdcTJ9uGKMLRaDVrK6SOeSkJR7iSND0omx/x0mMPRiUz/8wyfPVOOpk7Y14Yhv8CCHvrHbatHQr9F+sdwolyREaRikhEkIUpY0iU4tlI/ryj+vzvbLe2h0VPQpD/UaV3gisQ307PYF3WdXRFX2Xk2gairqUb7q5mb8KhPTdr5OdKuriN1nW3K75wV8dAOXbhB3zl70Gjg99fa08CtnP3/9LmdsPRpyMmEVi9Cj88LXUggHo6MIAkhyr/0JP2js3+Xw/ldwO2/10zMoV6w/hGaXzcwzTu6k5Wj45+YRHbenlh9NCbRaC6QVgMBHg60r6t/bNbMwwFzU3ndQ1UR6Fmdnk3d2PDvFT75/SRLng9SOyRj3u3hqXnwSygc+A7s3KHdWLWjEneRBEkIUbayM+HsZn1SdHoT5Nx5hQ+e7fSPzxo+mWfyqqIoRF5NZffZBHZGJLAv6hopGdlGbbwdq9GuriPt/Bx51Kcm9lbyctmq7O1gfzb/F8fOiAS2n46nU/28L0BXVeOn4WYs/DFRv5ikrZt+cUlRLkiCJIQofYoCMfv1SdF/a+DWjTv7nPz1I0VNngGHOkaHJaRkGMrvd59N4HJSutH+6tZmtKnreHuUyJHa1fN/l6KomurUtGZYG0/m7zzHJ7+fpF1dR0xNytkoYutX9BO298yCX0eDjbN+iQqhOkmQhBCl5+oZfVJ0bAUkRt/Zbuumrz5rOgBcmxjmXqRn5XDg3HV23U6KTly5p/zeVEtLr+qGydUN3ezQamXehijYmMf8WHnoImfiUljx90WeDarz4IPKWpcP9CNJx1bC8udg+AZwb6Z2VFWeJEhCiJJ1M05fffbvcv2rP3KZ2+ofnTXtD17tQWuiL7+/nHx7HtFVDp6/QeY95fcN3Oz05fd1HWlZjPJ7UbXZW5vxemc/3v/tBDM2n+HJZu7YWJSzX31aLfT+FlLi4dwO+LGffiHJ6l5qR1alSRVbMUkVmxB3yUiBU+v1SVHUdlBuJzlaU6jbRZ8U1esB5tZcvJFmWLF6T+Q1rt9Tfu9mb2mYR9S2riOONvIORPFwMrN1BM/8i3MJqbz6eF3e7FZf7ZDyl54MC0Mg7hjUrAsj/oRqNdWOqtIp7O9vSZCKSRIkUeXlZEPUNn1SdGoDZKXd2Ve7lT4pavQ0ySZ27I28ZkiKziUYl9/bWJjqy+/r1qSdnxO+TtWk/F6UuE3HY3l56SEszbRsG9cJN3srtUPKX/IV+L4bJEVD7ZYwdB2Yy9y6kiQJUimTBElUSYoClw7fWcQxLeHOvhq+0HQAWY2e4UhKdcN6RP/EJBq9XcNEq6GZhwPt6jrS3s+RAA8HzMrbxFlR6SiKwoB5+zhw/jpPP1KLGf2bqR1Swa6egQXd9MUM9XrAgKVgUs4eC1ZgkiCVMkmQRJVyPUr/DrR/l8P1yDvbrR1RGvfloscTbEmqxa6z19gXdY3UzByjw32cbpff13XkUd+a2FlK+b0oe/9eTOTJb3aj0cBvY9rRuJa92iEVLHof/NAbstPhkWHwxFeykGQJkQSplEmCJCq91AR9Sf6/y+HiwTvbTa1Ir9uDww7dWJNUj52RicQmG5ff16hmTtvb5fdt/Ryp5VBOH2eIKueNZUdYe/QyrX1q8tPIoPL9OPfkeljxnH5OX6dJ0OlttSOqFGQlbSFE0WWmwZmN+td9nN0COv1CjIpGyw3Xtuy0fIxF1xtx5GjuCFEsABamWlp516BdXf3Eaim/F+XVuOD6/H48lr1R1wg/GU+Xhi5qh1SwBr0g5AvYEAbbP9G/lPmRoWpHVWVIgiREVafLgXN/6ddgObEOMm8adsXbNGCTtgNzrzXn8rncv7T0yVEjdzva+TnSvq4TLbyqY2km5fei/Ktd3Zrn23kzZ3skn2w8Scf6TuV7DlzL5yH5Muz8An57A2xc9K/hEaVOEiQhqiJFgdhjtxdx/AVSYg27EkxdWZPdhmUZrYlMr2XYXsvBSj9C5OdIW9+a1JTye1FBvdLJlxUHY4i6msqyA9E819pL7ZDu7/HJcPMKHP0RVgyD4euhdgu1o6r0ZA5SMckcJFEhJcboR4r+XQFXTxo2J2PDuuwg1uS045BSD9Bga2HKo741DYs0ejtK+b2oPJbsu8C7a49To5o529/qVP4LB3Ky4OeB+kff1jXh+c1Q01ftqCokmaRdyiRBEhXGrRtw4ld0/yxHG73HsDlDMWOLrjlrc9qxXdcMRWtG8zoOtKvrRDs/RwJq25e/91YJUUKyc/SLR0ZeTeXljr5M6OGvdkgPlpECi3rqV6h38IQXtujf3SaKRBKkUiYJkijXsjNQzmwi5eDPWJ/fgomSBYBO0bBP14A1unZsymmFs5MT7f2cDOX35e4VDEKUovCTcTy/+G/MTbWEh3XEo0YFWJAxJV6/kOSNc+AWoH9vm4Wt2lFVKJIglTJJkES5o9Nx49QOEvcvxSVmE9a6FMOukzoP1ua0Y5dlR+r6+Rte5VFuVxMWogwoisLg/9vPnshrPBngzteDmqsdUuFci9QnSWkJ4NsZnl0OJuX8EWE5IglSKZMESZQHaZnZHDu6n6zDy/CL24iLctWw74pSg/VKW8659cSrUSva1XXC39VWyu+FuMt/l5PoNWsXigJrR7elmYeD2iEVzsVDsLiX/hU/AYOgzxxZSLKQZB0kISqhHJ3CsUtJHPnvJKYnVhGYtJkgzXnD/mTFin2W7bjm0wfP5l15zttRyu+FuI9G7vY83bw2qw5f5OMNJ1jxUuuKUYxQOxD6LdZP3P7nZ7Bzh85T1I6qUpEESYhyLvpaGjvPXuXv0xeoFrWJ4JwdDNP+h1ajgAayMOWM3aOk+/fFu01fujmU49cnCFEOvRVcnw3HLnPw/A3++C+W7o3d1A6pcOp107+CZN0Y2DkdbN2g1Ui1o6o0JEESopxJTMtkT+Q1dkYksC8iFu+kfTxlsotPtIex0mTC7QGheIfmmDQbQI2W/WlUraa6QQtRgbnaW/Jiex++3nqWTzee4nF/F8xNK0gF5yPP6ddI2vYx/P4W2LpCgyfUjqpSkARJCJVlZOdw+EIiu85eZVdEAv9eSqQZZ+ljsotxJvuoaX5nZet0ex/Mmg/CpGk/nGt4qxi1EJXLSx19+elADOevpbF03wVGtKtA/311eEu/2vahhfDL8zD0V/BsrXZUFZ5M0i4mmaQtiktRFE7H3WRXRAK7ziawP+o6t7Jy8NZcoY/Jbnprd+OljTO011VzRtvkGWjaH9yayURMIUrJzweimbj6GA7WZuwY9xj21hWoMiwnW/9i29O/g6UDjPgDnCvA2k4qkCq2UiYJkiiKuOR0Q0K062wCV29mAFCTJHqZ7KOf2R4aE3HnALNq+hdVNu0P3p3ARAZ7hShtOTqFkK92cjruJi+082Zyr4Zqh1Q0mWnwQ2+4eADsasMLm/WTt4URSZBKmSRI4n5SM7LZf04/j2hXRAIR8XfWJLIinZ7mh3nOej9NMg6jVfQvf0VjAr6PQ9MB4B8C5tVUil6IqmvHmasMW3AAMxMNW8I64lmzgv13mHZdv0bStQhwaQyhv4OlFG7cTRKkUiYJkijIrPAIvt4aQVbOnf+0TDU5DHY6Tz/zPTRI3IFJdtqdA9wf0SdFjZ+W1wYIUQ4MXXCAv85cpWcTN2YPfkTtcIruxgX4viukxIFXexiyCkzl5dK5ZB0kIVQQcz2NL7ecQaeAR3VL+te6Ti924nllI9rk+DsNq3vpk6Im/cGxrmrxCiHyeiekAbsirrLh2BVGXLhOoGcNtUMqmuqeMHglLOwJ53fC2lHw9P+BtoJU5pUTkiCVN7HHIemi2lGIYtr3dwyPaa4Q7HSN/uZ74OyZOzutauhHiZoOgNotZbK1EOVUfVdb+rfwYNnBGD7acJLVo9pUjMUj7+YWAAOWwI/PwPFV+jWSgj9WO6oKRR6xFVOpPWL77Q19qaaoHEwtoX6IfrK1b2cwNVc7IiFEIcTfTKfT/7aTlpnDrEHNeSKggk52/mc5rHlR/3XwJ9B6tLrxlAMV6hHb7Nmz+d///kdsbCwBAQHMmjWLVq1a5ds2KyuLadOmsXjxYi5dukT9+vX57LPP6N69u6GNl5cXFy5cyHPsK6+8wuzZswFIT0/nzTffZNmyZWRkZBAcHMy3336Li4tL6XSysBzq6OekiArnWmomMTfSsDA1wd/HC02jp/QLtlnKHDUhKhpnW0te7ujLjM1n+GzTKbo2dKmYr+0JGKBfSHLLVPhjEti4QJNn1I6qQlB9BGn58uUMHTqUuXPnEhQUxMyZM1m5ciWnT5/G2TnvhNW3336bpUuXMn/+fPz9/fnjjz8ICwtjz549NG+ufxPz1atXycnJMRxz/PhxunbtyrZt2+jUqRMAo0aNYsOGDSxatAh7e3vGjBmDVqtl9+7dhYpbJmmLuymKQvDMvzgTl8K7vRryfEVaZE4Ika9bmTl0+mIbcckZTArx58UOvmqHVDyKApsmwP65YGKun7Tt3UHtqFRTYarYgoKCaNmyJd988w0AOp0ODw8PXn31VSZMmJCnvbu7O++88w6jR98ZJuzbty9WVlYsXbo032u88cYbrF+/noiICDQaDUlJSTg5OfHTTz/xzDP6TPrUqVM0aNCAvXv38uijjz4wbkmQxN32nE3g2f/bj7W5CfsmdcbOsgItMCeEKNDKv2N465d/sbU0Zcdbj1GjWgV9TK7LgV9C4cSvYGEHoRvBtbHaUamisL+/VZ3SnpmZyaFDh+jSpYthm1arpUuXLuzduzffYzIyMrC0tDTaZmVlxa5duwq8xtKlSxkxYoRhkt2hQ4fIysoyuq6/vz916tS573WTk5ONPkLkWrjnPAB9H6ktyZEQlUjfR2rT0M2Om+nZfB0e8eADyiutCTz1HXi2hYxk/eTtxBi1oyrXVE2QEhISyMnJyTPvx8XFhdjY2HyPCQ4OZsaMGURERKDT6di8eTOrV6/mypUr+bZfu3YtiYmJDB8+3LAtNjYWc3NzHBwcCn3dadOmYW9vb/h4eHgUvqOiUou5nkb4Sf2rQYa18VQ5GiFESdJqNUzu2QCApfsuEHU15QFHlGNmljDwR3BqoJ+XtLSvfmFJka8KtyjCV199hZ+fH/7+/pibmzNmzBhCQ0PRFrC+w/fff0+PHj1wd3+4CoSJEyeSlJRk+MTESOYt9Jbsu4BOgfZ+jtR1tlU7HCFECWtT15HO/s5k6xQ+3XhK7XAejlV1GPIL2LpDwmn4eRBk3VI7qnJJ1QTJ0dERExMT4uLijLbHxcXh6uqa7zFOTk6sXbuW1NRULly4wKlTp7CxscHHxydP2wsXLrBlyxZeeOEFo+2urq5kZmaSmJhY6OtaWFhgZ2dn9BEiLTObZQeiAQht66VuMEKIUjMxxB8TrYY/T8SxL+qa2uE8HPva+onaFvYQsw9Wj9TPURJGVE2QzM3NCQwMJDw83LBNp9MRHh5O69at73uspaUltWrVIjs7m1WrVtG7d+88bRYuXIizszM9e/Y02h4YGIiZmZnRdU+fPk10dPQDryvE3dYcuURyejaeNa3pVE9eEyJEZVXX2ZZBrfRTKz7ecBKdroIvIejSEAb9pK9qO/kbbHxbX+0mDFR/xBYWFsb8+fNZvHgxJ0+eZNSoUaSmphIaGgrA0KFDmThxoqH9/v37Wb16NVFRUezcuZPu3buj0+kYP3680Xl1Oh0LFy5k2LBhmJoaL/dkb2/P888/T1hYGNu2bePQoUOEhobSunXrQlWwCQH60v7FtydnD23thVZbwVbaFUIUyRtd6mFjYcqxS0n8+s8ltcN5eF7t4OnvAA0cnA+7vlQ7onJF9YUiBwwYwNWrV5kyZQqxsbE0a9aMTZs2GSZuR0dHG80vSk9PZ/LkyURFRWFjY0NISAhLlizJM+F6y5YtREdHM2LEiHyv++WXX6LVaunbt6/RQpFCFNbeyGuciUvB2tyEfi1qqx2OEKKUOdpY8Mpjvny+6TT/23SaHo3dKubikXdr9BTcjINNb0P4+/pXkjQbpHZU5YLq6yBVVLIOkhj5w99sPhHH0NaefNC7aq4nIkRVk56VQ+fpO7iUeIu3gusz+rFK8rLpP9+FPV+D1hSeXQ51uzz4mAqqQqyDJERFFXM9jS23S/uHtvZSNxghRJmxNDPhreD6AMzZHklCSobKEZWQLu9Dk/6gy4blQ+HyEbUjUp0kSEIUww97z6Mo0KGeE3WdbdQORwhRhp4McKdpbXtSMrL5cvMZtcMpGVot9J4N3h0hKxV+7AfXz6kdlaokQRKiiFIzsll2UL8O1nBZGFKIKker1fBOiH7xyGUHY4iIu6lyRCXE1BwGLAWXJpB6Vb+QZGqC2lGpRhIkIYpozZFL3JTSfiGqtCCfmnRr6EKOTmFaRV888m6WdvqFJO3rwPVI+Kk/ZKaqHZUqJEESogjuLu0fJqX9QlRpE3r4Y6rVsPVUPLvPVqKRFltX/UKSVtXh0iH4ZQTkZKsdVZmTBEmIItgTeY2I+BSqmZvwjJT2C1Gl+TjZMORR/WP2jzacJKeiLx55N6d6MGg5mFrCmU2wYWyVW0hSEiQhimDh7vMAPBNYGztLM3WDEUKo7vXOfthZmnLySjKrDl9UO5ySVScInlkAGi0c/gF2fKZ2RGVKEiQhCin6Whrhp26X9rfxUjcYIUS5UL2aOa8+7gfA9D9Pk5ZZyR5F+feEntP1X2+fBocWqRpOWZIESYhCuru039dJSvuFEHpD23jiUcOKuOQM5v9VCUvjW4yADm/pv14/Fk5vUjeeMiIJkhCFkJqRzfK/9aX9oTJ6JIS4i4WpCW939wdg3l+RxCenqxxRKXjsHWg2BBQdrBwOF/9WO6JSJwmSEIWQW9rvVdOajvWc1A5HCFHO9GzixiN1HEjLzGH6n5Vk8ci7aTTwxEyo2xWyb+kXkkw4q3ZUpUoSJCEeQFEUFuWW9reR0n4hRF4ajYZ3ejYEYMWhGE5eSVY5olJgYgb9FoF7c7h1HZY+rX/RbSUlCZIQD7D77DXO5pb2B0ppvxAif4Ge1enZxA1FgU9+P6l2OKXDwgaeXQnVvSHxAvzUDzIqyUri95AESYgHWLRHP+nymcDa2EppvxDiPt7u7o+5iZadEQlsPx2vdjilw8ZJv5CktSNc+QdWDIXsTLWjKnGSIAlxH/rSfv3/yUlpvxDiQerUtGbY7Xc0fvL7SbJzdCpHVEpq+sLgFWBmDZFbYd2rlW4hSUmQhLiP3NL+jlLaL4QopDGP+eFgbcaZuBRWHqpki0ferVYg9P8BNCbw7zIIf1/tiEqUJEhCFODu0v7hbb3UDUYIUWHYW5vxmmHxyDOkZFSyxSPv5tcVnvxa//WuL2H/d+rGU4IkQRKiAKtvl/Z7O1ajo5+U9gshCm/Io5541bQmISWDeTsi1Q6ndDUfAo9N1n+9cTycWKduPCVEEiQh8qEoCot26ydnD2vtKaX9QogiMTfVMqFHAwDm74ziStItlSMqZR3G6VfcRoFVL8CFPWpH9NAkQRIiH7vOJhB5NZVq5ib0ldJ+IUQxBDdyoZVXDdKzdPzvj9Nqh1O6NBoI+QLq94ScDPh5IMSfUjuqhyIJkhD5WLT7PAD9WnhIab8Qolj0i0fqR5HWHLnE8UtJKkdUyrQm8Mz34BEE6UmwtC8kX1Y7qmKTBEmIe1y4lsrW2+uXDG3tqXI0QoiKLMDDgd7N3FEU+HjDSZRKVgqfh5kVDFoGNf0g+SIsfQZuJaodVbFIgiTEPX7YewFFgU71nfCR0n4hxEN6K7g+5qZa9kZdI/xkJV088m7WNfQLSdq4QPx/sHwIZGeoHVWRSYIkxF1SM7JZcfB2ab8sDCmEKAG1q1vzfDtvAD7ZeJKsyrp45N2qe8LgX8DcFs7vhDUvga5i9VsSJCHusvrwRW5m6Ev7O0hpvxCihIzq5EuNauZEXU1l2YFotcMpG25NYeBS0JrBf2vgz8lqR1QkkiAJcZuiKCzacx6Q0n4hRMmyszRjbBf94pFfbokgOT1L5YjKiE8n6DNH//W+2bDnG1XDKQpJkIS4Lbe038bCVEr7hRAlblCrOvg6VeN6aibfbqvki0ferWk/6Pqh/us/34Fjv6gbTyFJgiTEbbml/c8E1pbSfiFEiTM10TIpRF/2v2D3OWKup6kcURlq8yoEjdJ/veZliNqhbjyFIAmSEMD5hDul/cNkcrYQopQ87u9MG9+aZGbr+OLPSr545N00Ggj+BBr2AV2WvrIt9pjaUd2XJEhCcKe0/7H6Tng7VlM7HCFEJaXRaJgU0gCNBn49epmjMYlqh1R2tFp4ah54toOMZP0aSYnld8K6JEiiykvJyGbl3/rSfhk9EkKUtsa17Hm6uX6e48cbTlT+xSPvZmYJA38EpwaQEqtfbTvtutpR5Uv1BGn27Nl4eXlhaWlJUFAQBw4cKLBtVlYWH3zwAb6+vlhaWhIQEMCmTZvytLt06RJDhgyhZs2aWFlZ0aRJE/7++2/D/uHDh6PRaIw+3bt3L5X+ifIvt7TfR0r7hRBl5K3g+liaaTl4/gZ//Berdjhly8pBv5CkXS1IOAM/D4Ks8vcyX1UTpOXLlxMWFsbUqVM5fPgwAQEBBAcHEx+f/0qjkydPZt68ecyaNYsTJ07w8ssv89RTT3HkyBFDmxs3btC2bVvMzMzYuHEjJ06cYPr06VSvXt3oXN27d+fKlSuGz88//1yqfRXlk06nsDi3tL+Nl5T2CyHKhKu9JS+29wHg042nyMyuWIsoPjT7WvokydIeYvbBqhdAl6N2VEY0iopje0FBQbRs2ZJvvtGvi6DT6fDw8ODVV19lwoQJedq7u7vzzjvvMHr0aMO2vn37YmVlxdKlSwGYMGECu3fvZufOnQVed/jw4SQmJrJ27dpix56cnIy9vT1JSUnY2dkV+zxCXX+ducrQBQewsTBl36TO2FiYqh2SEKKKSMnIptP/tpOQksGUXg0ZcXu17Srl/G5Y8hTkZEDLFyDkC/2E7lJU2N/fqo0gZWZmcujQIbp06XInGK2WLl26sHfv3nyPycjIwNLS0miblZUVu3btMny/bt06WrRoQb9+/XB2dqZ58+bMnz8/z7m2b9+Os7Mz9evXZ9SoUVy7du2+8WZkZJCcnGz0ERVf7sKQ/VrUluRICFGmbCxMebNbPQC+3hpBUloVWTzybl5t4envAA0c/D/YOV3tiAxUS5ASEhLIycnBxcXFaLuLiwuxsfk/jw0ODmbGjBlERESg0+nYvHkzq1ev5sqVK4Y2UVFRzJkzBz8/P/744w9GjRrFa6+9xuLFiw1tunfvzg8//EB4eDifffYZO3bsoEePHuTkFDy8N23aNOzt7Q0fDw+Ph/wJCLWdS0hl6yn949yhrb3UDUYIUSX1b+FBfRdbEtOymLU1Qu1w1NGoD/T4TP/11g/hyI+qhpNL9UnaRfHVV1/h5+eHv78/5ubmjBkzhtDQULTaO93Q6XQ88sgjfPLJJzRv3pwXX3yRkSNHMnfuXEObgQMH8uSTT9KkSRP69OnD+vXrOXjwINu3by/w2hMnTiQpKcnwiYmJKc2uijLww97zgJT2CyHUY6LVMKmnfvHIxXvPc+FaqsoRqSToJWj7uv7rda9CxBZ140HFBMnR0RETExPi4uKMtsfFxeHq6prvMU5OTqxdu5bU1FQuXLjAqVOnsLGxwcfHx9DGzc2Nhg0bGh3XoEEDoqMLXmvBx8cHR0dHzp49W2AbCwsL7OzsjD6i4krJyOaXvy8CMLxtFXzuL4QoNzrWc6K9nyNZOQqfb6pCi0feq/N70HQAKDmwYihcOqxqOKolSObm5gQGBhIeHm7YptPpCA8Pp3Xr1vc91tLSklq1apGdnc2qVavo3bu3YV/btm05fdr4H9iZM2fw9PQs8HwXL17k2rVruLm5FbM3oqIxlPY7VaN9XUe1wxFCVHHv9GyAVgMbjl3h0IXyuS5QqdNq4clv9C+4zUqFn/rD9Sj1wlHtykBYWBjz589n8eLFnDx5klGjRpGamkpoaCgAQ4cOZeLEiYb2+/fvZ/Xq1URFRbFz5066d++OTqdj/PjxhjZjx45l3759fPLJJ5w9e5affvqJ7777zlD5lpKSwltvvcW+ffs4f/484eHh9O7dm7p16xIcHFy2PwChCp1OMUzOHi6l/UKIcsDf1Y7+LfRzWz/acLJqLR55N1Nz6L8EXJtA6lU4+L16oah2ZWDAgAFcvXqVKVOmEBsbS7Nmzdi0aZNh4nZ0dLTR/KL09HQmT55MVFQUNjY2hISEsGTJEhwcHAxtWrZsyZo1a5g4cSIffPAB3t7ezJw5k8GDBwNgYmLCv//+y+LFi0lMTMTd3Z1u3brx4YcfYmFhUab9F+rYeTaBqKup2FqY8vQjtdUORwghAAjrWo91/1zmSHQi6/+9whMB7mqHpA5LOxi8Cg4vhvbjVAtD1XWQKjJZB6niCl14gG2nrxLa1oupTzRSOxwhhDD4aksEX245Q+3qVoS/2RELUxO1Q6p0yv06SEKo4VxCKttOX0WjgWFS2i+EKGdGdvDGxc6CizduGVb5F+qQBElUKXdK+53xktJ+IUQ5Y21uyrhu9QGYtfUs11MzVY6o6pIESVQZKRnZrMwt7W/jpW4wQghRgKcfqU1DNztupmfzdXgVXTyyHJAESVQZqw5dJCUjG1+narT3k9J+IUT5ZKLV8M7txSOX7rtA1NUUlSOqmiRBElWCTqcYnucPa+OFppRfhiiEEA+jbV1HHvd3Jlun8OnGU2qHUyVJgiSqhL8irhKVIKX9QoiKY1KIPyZaDX+eiGNf1P1fqC5KniRIokrIHT3q18IDGwtVl/8SQohCqetsy6BW+sUjP95wEp1OVuUpS5IgiUrv7tL+oa0LfuWMEEKUN290qYeNhSnHLiXx6z+X1A6nSpEESVR6uaNHj0tpvxCignG0sWBUJ18A/rfpNOlZOSpHVHVIgiQqtZvpWfxy6HZpf1svdYMRQohieL6dN7UcrLiclM73u86pHU6VIQmSqNTuLu1vV1dK+4UQFY+lmQlvBesXj5yzPZKElAyVI6oaJEESlZZOp7B47wVAvzCklPYLISqqJwPcaVrbnpSMbL7cfEbtcKoESZBEpfVXxFXOSWm/EKIS0Go1vBOiXzxy2cEYIuJuqhxR5ScJkqi0Ft2enN2/pQfVpLRfCFHBBfnUpFtDF3J0CtNk8chSJwmSqJSirqawXUr7hRCVzIQe/phqNWw9Fc/uswlqh1OpSYIkKqUfbs896uzvjGdNKe0XQlQOPk42DHlU/0ffRxtOkiOLR5YaSZBEpXMzPYuVf8cA+veuCSFEZfJaZz9sLU05eSWZ1Ycvqh1OpSUJkqh0Vh26SGpmDnWdbaS0XwhR6dSoZs6rj9cF4Is/T5OWma1yRJWTJEiiUrm7tH+YlPYLISqpYW288KhhRVxyBvP/ksUjS4MkSKJS2ZFb2m9pytPNa6kdjhBClAoLUxPe7u4PwLy/IolPTlc5ospHEiRRqSzafR6AAS2ktF8IUbn1bOJG8zoOpGXmMP1PWTyypBUrQTp48CD79+/Ps33//v38/fffDx2UEMUReTWFHWdyS/u91A5HCCFKlUajYXJP/eKRKw7FcPJKssoRVS7FSpBGjx5NTExMnu2XLl1i9OjRDx2UEMXxw+2FITv7O1OnprW6wQghRBkI9KxBzyZuKAp88vtJtcOpVIqVIJ04cYJHHnkkz/bmzZtz4sSJhw5KiKK6mZ7FL4f05a7D23irHI0QQpSdt7v7Y2aiYWdEAttPx6sdTqVRrATJwsKCuLi4PNuvXLmCqanM+xBl75e7Svvb1q2pdjhCCFFm6tS0ZtjtaQWf/H6S7BydugFVEsVKkLp168bEiRNJSkoybEtMTGTSpEl07dq1xIITojB0OoXFtx+vDZfSfiFEFfTq4344WJtxJi6FlYdk8ciSUKwE6YsvviAmJgZPT08ee+wxHnvsMby9vYmNjWX69OklHaMQ97XjzFXOX0vTl/Y/IqX9Qoiqx97ajNce9wNg+p9nSMmQxSMfVrESpFq1avHvv//y+eef07BhQwIDA/nqq684duwYHh4eJR2jEPe18Pbo0YAWHlibyyNeIUTVNORRT7xqWpOQksG8HZFqh1PhFfu3SbVq1XjxxRdLMhYhiizyagp/SWm/EEJgbqplQo8GvLz0EPN3RvFsUB3c7K3UDqvCKnSCtG7dOnr06IGZmRnr1q27b9snn3zyoQMTojDulPa7SGm/EKLKC27kQiuvGhw4f50v/jjD9P4BaodUYWkURVEK01Cr1RIbG4uzszNabcFP5jQaDTk5OSUWYHmVnJyMvb09SUlJ2NnZqR1OlZScnkXrT8JJzczhxxeCaCsvphVCCP6JSaT37N1oNPDbmHY0rmWvdkjlSmF/fxd6DpJOp8PZ2dnwdUGfoiZHs2fPxsvLC0tLS4KCgjhw4ECBbbOysvjggw/w9fXF0tKSgIAANm3alKfdpUuXGDJkCDVr1sTKyoomTZoYrfCtKApTpkzBzc0NKysrunTpQkRERJHiFur75W99ab+fsw1tfKW0XwghAAI8HOjdzB1FgY83nKSQ4yDiHkWepJ2VlUXnzp1LJKFYvnw5YWFhTJ06lcOHDxMQEEBwcDDx8fkvdDV58mTmzZvHrFmzOHHiBC+//DJPPfUUR44cMbS5ceMGbdu2xczMjI0bN3LixAmmT59O9erVDW0+//xzvv76a+bOncv+/fupVq0awcHBpKfLy/4qCp1OYfHe84D+rdZS2i+EEHe8FVwfc1Mte6OuEX5SFo8sjkI/Yrubk5MTe/bswc/P76EuHhQURMuWLfnmm28A/ciUh4cHr776KhMmTMjT3t3dnXfeecfodSZ9+/bFysqKpUuXAjBhwgR2797Nzp07872moii4u7vz5ptvMm7cOACSkpJwcXFh0aJFDBw4sFCxyyM2dW09FceIRX9ja2nK/kmdpXpNCCHu8enGU8zdEYmPUzX+eKMDZibyfnoohUdsdxsyZAjff/99sYMDyMzM5NChQ3Tp0uVOMFotXbp0Ye/evfkek5GRgaWlpdE2Kysrdu3aZfh+3bp1tGjRgn79+uHs7Ezz5s2ZP3++Yf+5c+eIjY01uq69vT1BQUEFXleUP4v2XABgYEsp7RdCiPy88pgvNaqZE3U1lWUHotUOp8Ip1m+W7OxsFixYwJYtWwgMDKRatWpG+2fMmPHAcyQkJJCTk4OLi4vRdhcXF06dOpXvMcHBwcyYMYMOHTrg6+tLeHg4q1evNpr3FBUVxZw5cwgLC2PSpEkcPHiQ1157DXNzc4YNG0ZsbKzhOvdeN3dffjIyMsjIyDB8n5wsb01Wy9l4Ke0XQogHsbM0Y2wXP9799T++3BJB7+a1sLM0UzusCqNYCdLx48cNL6s9c+ZMiQZ0P1999RUjR47E398fjUaDr68voaGhLFiwwNBGp9PRokULPvnkE0D/At3jx48zd+5chg0bVuxrT5s2jffff/+h+yAe3g+35x51aeCCRw0p7RdCiIIMbFWHRXvOE3k1lW+3RTKhh7/aIVUYxUqQtm3b9tAXdnR0xMTEJM9Lb+Pi4nB1dc33GCcnJ9auXUt6ejrXrl3D3d2dCRMm4OPjY2jj5uZGw4YNjY5r0KABq1atAjCcOy4uDjc3N6PrNmvWrMB4J06cSFhYmOH75ORkWTVcBcnpWfxy+z1DoW281A1GCCHKOTMTLRN7NOCFH/5mwe5zDA6qI39YFlKx5iCNGDGCmzdv5tmemprKiBEjCnUOc3NzAgMDCQ8PN2zT6XSEh4fTunXr+x5raWlJrVq1yM7OZtWqVfTu3duwr23btpw+fdqo/ZkzZ/D09ATA29sbV1dXo+smJyezf//++17XwsICOzs7o48oeyv/vkhaZg71XGxoLaX9QgjxQJ0bONPapyaZ2Tq++PP0gw8QQDETpMWLF3Pr1q0822/dusUPP/xQ6POEhYUxf/58Fi9ezMmTJxk1ahSpqamEhoYCMHToUCZOnGhov3//flavXk1UVBQ7d+6ke/fu6HQ6xo8fb2gzduxY9u3bxyeffMLZs2f56aef+O677wyVbxqNhjfeeIOPPvqIdevWcezYMYYOHYq7uzt9+vQpzo9DlBGdTjE8XpPSfiGEKByNRsM7PRug0cCvRy9zNCZR7ZAqhCI9YktOTkZRFBRF4ebNm0YVZTk5Ofz++++GxSQLY8CAAVy9epUpU6YQGxtLs2bN2LRpk2ECdXR0tNGq3enp6UyePJmoqChsbGwICQlhyZIlODg4GNq0bNmSNWvWMHHiRD744AO8vb2ZOXMmgwcPNrQZP348qampvPjiiyQmJtKuXTs2bdqUp0JOlC/bz8Rz4VoadpamPNW8ltrhCCFEhdG4lj1PN6/NqsMX+XjDCVa81Fr+yHyAIq2DpNVq7/sD1Wg0vP/++7zzzjslElx5Jusglb3nvt/PzogEXuzgw6SQBmqHI4QQFcqVpFs89sV20rN0zB3yCN0buz34oEqosL+/izSCtG3bNhRF4fHHH2fVqlXUqFHDsM/c3BxPT0/c3d2LH7UQBTgbf5OdEQloNfDco55qhyOEEBWOm70VI9v7MGvrWT7deIrH/V0wN5XFIwtSpASpY8eOgH6xxTp16sjwnCgzi28vDNlZSvuFEKLYXuroy88HYjh/LY2l+y4wop232iGVW8VKHT09Pdm1axdDhgyhTZs2XLp0CYAlS5YYrWotRElITs9i1WEp7RdCiIdlY2HKm93qAfD11giS0rJUjqj8KlaCtGrVKoKDg7GysuLw4cOGFaaTkpIMCzQKUVKktF8IIUpOv8Da1HOxITEti1lbH/7F85VVsRKkjz76iLlz5zJ//nzMzO4sW962bVsOHz5cYsEJkaNTWLznPADD23jLY10hhHhIpiZaQ6HL4r3nuXAtVeWIyqdiJUinT5+mQ4cOebbb29uTmJj4sDEJYbD9dDzR19OwtzKjT3MpABBCiJLQqb4z7f0cycpR+HyTLB6Zn2IlSK6urpw9ezbP9l27dhm99kOIh7Xo9ujRwJYeWJsX6804Qggh8vFOzwZoNbDh2BUOXbiudjjlTrESpJEjR/L666+zf/9+NBoNly9f5scff2TcuHGMGjWqpGMUVdTdpf1DpLRfCCFKlL+rHf0C9e8U/WjDSYqwLGKVUKw/ySdMmIBOp6Nz586kpaXRoUMHLCwsGDduHK+++mpJxyiqqNzS/i5S2i+EEKXizW71+O3fyxyJTmT9v1d4IkCmMuQq1giSRqPhnXfe4fr16xw/fpx9+/Zx9epVPvzww5KOT1RRSbfulPYPb+ulbjBCCFFJOdtZ8lIHXwA+23SKjOwclSMqP4o0gjRixIhCtVuwYEGxghEi18q/Y0jLzKG+iy2tfaS0XwghSsvIDt78dOACF2/cYvGe87x4O2Gq6oo0grRo0SK2bdtGYmIiN27cKPAjxMPI0Sn8sFf/eG14Wy8p7RdCiFJkbW7KuG71AZi19SzXUzNVjqh8KNII0qhRo/j55585d+4coaGhDBkyxOh9bEKUhG2n7irtb1ZL7XCEEKLSe/qR2izYfZ6TV5L5OjyC955spHZIqivSCNLs2bO5cuUK48eP57fffsPDw4P+/fvzxx9/yOx3UWLuLu23MjdRNxghhKgCTLQaJvfULx65dN8Foq6mqByR+oo8SdvCwoJBgwaxefNmTpw4QaNGjXjllVfw8vIiJUV+oOLhRMTdZNdZKe0XQoiy1rauI4/7O5OtU/h04ym1w1FdsarYDAdrtWg0GhRFISdHZr6Lh7d473kAujaU0n4hhChrk0L8MdFq+PNEHPuirqkdjqqKnCBlZGTw888/07VrV+rVq8exY8f45ptviI6OxsbGpjRiFFVE0q0sVh26BOjfuyaEEKJs1XW2ZWBL/eKRH284iU5XdafPFClBeuWVV3Bzc+PTTz+lV69exMTEsHLlSkJCQtBqH2owSghW/h3Drawc/F1tedRHJv8LIYQaxnath42FKccuJfHrP5fUDkc1GqUIs6u1Wi116tShefPm9y29Xr16dYkEV54lJydjb29PUlISdnZ2aodT4eXoFDp9sY2Y67eY9nQTBrWqo3ZIQghRZc3edpb//XEad3tLto7rhKVZ5SmYKezv7yKV+Q8dOlTWpBGlYtupeGKu35LSfiGEKAeeb+fNj/sucDkpne93nWP0Y3XVDqnMFSlBWrRoUSmFIao6Q2l/KyntF0IItVmamfBW9/qMXf4Pc7ZHMqClB442FmqHVaZk4pBQ3d2l/c9Jab8QQpQLvQNq0bS2PSkZ2Xy5+Yza4ZQ5SZCE6nJHj7o1dKV2dSntF0KI8kCr1fBOiH7xyGUHY4iIu6lyRGVLEiShqqS0LFYf1ldJDGvjpW4wQgghjAT51KRbQxdydArTqtjikZIgCVWtkNJ+IYQo1yb08MdUq2HrqXh2n01QO5wyIwmSUE2OTuGHfecBGN7GSyokhRCiHPJxsjG8+umjDSfJqSKLR0qCJFSz9XZpv4O1Gb2ltF8IIcqt1zr7YWtpyskryaw+fFHtcMqEJEhCNYv2nANgYMs6UtovhBDlWI1q5rz6uH4tpC/+PE1aZrbKEZU+SZCEKs7E3WT32Wv60v7WUtovhBDl3dDWXtSubkVccgbz/zqndjilThIkoYq7S/trOVipG4wQQogHsjQz4e3u/gDM+yuS+OR0lSMqXZIgiTKXlJbFmtul/cPbeqkbjBBCiELr1dSN5nUcSMvMYUYlXzyyXCRIs2fPxsvLC0tLS4KCgjhw4ECBbbOysvjggw/w9fXF0tKSgIAANm3aZNTmvffeQ6PRGH38/f2N2nTq1ClPm5dffrlU+ieM3V3aH+Qtpf1CCFFRaDQaJvfULx654u8YTsUmqxxR6VE9QVq+fDlhYWFMnTqVw4cPExAQQHBwMPHx8fm2nzx5MvPmzWPWrFmcOHGCl19+maeeeoojR44YtWvUqBFXrlwxfHbt2pXnXCNHjjRq8/nnn5dKH8UdOTqFxXvPAxDaVkr7hRCiogn0rEHPJm7oFPh4w0m1wyk1qidIM2bMYOTIkYSGhtKwYUPmzp2LtbU1CxYsyLf9kiVLmDRpEiEhIfj4+DBq1ChCQkKYPn26UTtTU1NcXV0NH0dHxzznsra2NmpjZ2dXKn0Ud4SfjOPiDSntF0KIimx89/qYmWjYGZHA9tP5D2hUdKomSJmZmRw6dIguXboYtmm1Wrp06cLevXvzPSYjIwNLS0ujbVZWVnlGiCIiInB3d8fHx4fBgwcTHR2d51w//vgjjo6ONG7cmIkTJ5KWllYCvRL3kzs5e2DLOliaSWm/EEJURJ41qzGstRcAn/x+kuwcnboBlQJVE6SEhARycnJwcXEx2u7i4kJsbGy+xwQHBzNjxgwiIiLQ6XRs3ryZ1atXc+XKFUOboKAgFi1axKZNm5gzZw7nzp2jffv23Lx550V7zz77LEuXLmXbtm1MnDiRJUuWMGTIkAJjzcjIIDk52egjiuZ07E32REppvxBCVAavPu6Hg7UZZ+JSWHmo8i0eaap2AEX11VdfMXLkSPz9/dFoNPj6+hIaGmr0SK5Hjx6Gr5s2bUpQUBCenp6sWLGC559/HoAXX3zR0KZJkya4ubnRuXNnIiMj8fX1zXPdadOm8f7775dizyq/3LlHwY2ktF8IISo6e2szXnvcjw/Wn2D6n2d4IsAdG4sKl1YUSNURJEdHR0xMTIiLizPaHhcXh6ura77HODk5sXbtWlJTU7lw4QKnTp3CxsYGHx+fAq/j4OBAvXr1OHv2bIFtgoKCAApsM3HiRJKSkgyfmJiYB3VP3CUpLcuwPP3wNl7qBiOEEKJEDHnUE6+a1iSkZDBvR6Ta4ZQoVRMkc3NzAgMDCQ8PN2zT6XSEh4fTunXr+x5raWlJrVq1yM7OZtWqVfTu3bvAtikpKURGRuLm5lZgm6NHjwIU2MbCwgI7Ozujjyi85X9Hk56lo4GbHa2ktF8IISoFc1MtE3rol9GZvzOKK0m3VI6o5KhexRYWFsb8+fNZvHgxJ0+eZNSoUaSmphIaGgrA0KFDmThxoqH9/v37Wb16NVFRUezcuZPu3buj0+kYP368oc24cePYsWMH58+fZ8+ePTz11FOYmJgwaNAgACIjI/nwww85dOgQ58+fZ926dQwdOpQOHTrQtGnTsv0BVAE5OoXFey4AENpGSvuFEKIyCW7kSiuvGqRn6fjij8qzeKTqDwsHDBjA1atXmTJlCrGxsTRr1oxNmzYZJm5HR0ej1d7J49LT05k8eTJRUVHY2NgQEhLCkiVLcHBwMLS5ePEigwYN4tq1azg5OdGuXTv27duHk5MToB+52rJlCzNnziQ1NRUPDw/69u3L5MmTy7TvVcWWk3FcSrxFdWsznmzmrnY4QgghSpBGo2FSzwb0mb2b1UcuEtrWi8a17NUO66FpFEVR1A6iIkpOTsbe3p6kpCR53PYAz87fx57Ia4zq5Gt4j48QQojK5bWfj7Dun8u09qnJTyODyu3TgsL+/lb9EZuo3HJL+020GoY8KqX9QghRWY3vXh9zUy17o64RfrLiLx4pCZIoVbkLQwY3cpHSfiGEqMRqV7dmRFtvAD7ZeJKsCr54pCRIotQkpmWy5khuab+3ytEIIYQoba885kuNauZEXU1l2YG8b7CoSCRBEqVm+cEYQ2l/S6/qaocjhBCilNlZmvFGFz8AvtwSQXJ6lsoRFZ8kSKJU5OgUftgrpf1CCFHVDGpVBx+nalxPzeTbbRV38UhJkESpkNJ+IYSomsxMtEzq0QCABbvPEXO9Yr4IXhIkUSoW7T4P6P+SsDQzUTcYIYQQZapzA2da+9QkM1vHF3+eVjucYpEESZS4U7HJ7I2S0n4hhKiqNBoN7/RsgEYDvx69zNGYRLVDKjJJkESJW3y7tL97I1fcpbRfCCGqpMa17HmqeS0APt5wgoq2LrUkSKJE6Uv7LwEwrI2XusEIIYRQ1VvB9bE003Lw/A3++C9W7XCKRBIkUaJyS/sbSmm/EEJUeW72Voxs7wPApxtPkZldcRaPlARJlJjsHJ2htH94WyntF0IIAS919MXRxoLz19JYuu+C2uEUmiRIosRsORnPpcRb1KhmzpMBUtovhBACbCxMCetaD4Cvt0aQlFYxFo+UBEmUmEV7zgEwqJWHlPYLIYQw6N+iNvVcbEhMy2LW1gi1wykUSZBEiTh5JZl9UdeltF8IIUQepiZaJoXoF49cvPc80dfK/+KRkiCJEnF3ab+bvZT2CyGEMNapvjPt/RzJylH4bNMptcN5IEmQxEO7kZrJ2qP60v7hbb3UDUYIIUS5NSlEv3jkhmNXOHThutrh3JckSOKhLf9bX9rfyN2OFp5S2i+EECJ/Ddzs6B/oAcBHG06W68UjJUESDyU7R8eS3NL+NlLaL4QQ4v7e7FYPa3MTjkQnsv7fK2qHUyBJkMRD2XIyzlDa/4SU9gshhHgAZztLXurgC8Bnm06RkZ2jckT5kwRJPJSFu88DUtovhBCi8EZ28MbFzoKLN24ZinzKG0mQRLGdvJLM/nNS2i+EEKJorM1NebNbfQBmbT3L9dRMlSPKSxIkUWyG0v7GUtovhBCiaPo+UpsGbnbcTM/m6/Dyt3ikJEiiWG6kZrLmiL60P7SNl7rBCCGEqHBMtBom99QvHrl03wWirqaoHJExSZBEsSw7GENGto7GtewIlNJ+IYQQxdC2riOP1XciW6fw6cbytXikJEiiyPSl/ecBGNZaSvuFEEIU36SQBphoNfx5Io59UdfUDsdAEiRRZJtPxHE5KV1K+4UQQjw0PxdbBrbULx758YaT6HTlY/FISZBEkS26PTn72VZ1pLRfCCHEQxvbtR42FqYcu5TEun8uqx0OIAmSKKITl6W0XwghRMlytLFgVCf94pGfbzpFepb6i0dKgiSKJLe0v0djV1ztLdUNRgghRKXxfDtv3O0tuZyUzve7zqkdjiRIovCup2ay9ujt0v62XuoGI4QQolKxNDPhre76xSPnbI8kISVD1XjKRYI0e/ZsvLy8sLS0JCgoiAMHDhTYNisriw8++ABfX18sLS0JCAhg06ZNRm3ee+89NBqN0cff39+oTXp6OqNHj6ZmzZrY2NjQt29f4uLiSqV/lcWyg9GG0v5H6khpvxBCiJLVO6AWTWvbk5KRzZebz6gai+oJ0vLlywkLC2Pq1KkcPnyYgIAAgoODiY+Pz7f95MmTmTdvHrNmzeLEiRO8/PLLPPXUUxw5csSoXaNGjbhy5Yrhs2vXLqP9Y8eO5bfffmPlypXs2LGDy5cv8/TTT5daPyu67BwdS/deAGB4G28p7RdCCFHitFoNk0L0i0cuOxhDRNxN9WJR7cq3zZgxg5EjRxIaGkrDhg2ZO3cu1tbWLFiwIN/2S5YsYdKkSYSEhODj48OoUaMICQlh+vTpRu1MTU1xdXU1fBwdHQ37kpKS+P7775kxYwaPP/44gYGBLFy4kD179rBv375S7W9FlVvaX7OaOb2auqkdjhBCiErqUZ+adG3oQo5O4ZdDF1WLQ9UEKTMzk0OHDtGlSxfDNq1WS5cuXdi7d2++x2RkZGBpaTw52MrKKs8IUUREBO7u7vj4+DB48GCio6MN+w4dOkRWVpbRdf39/alTp06B163qFuaW9gdJab8QQojSNSmkAbOffYQJPfwf3LiUqJogJSQkkJOTg4uLi9F2FxcXYmNj8z0mODiYGTNmEBERgU6nY/PmzaxevZorV64Y2gQFBbFo0SI2bdrEnDlzOHfuHO3bt+fmTf1QXWxsLObm5jg4OBT6uhkZGSQnJxt9qor/Lidx4Nx1TLUaBgdJab8QQojS5e1YjZ5N3VSdzqH6I7ai+uqrr/Dz88Pf3x9zc3PGjBlDaGgoWu2drvTo0YN+/frRtGlTgoOD+f3330lMTGTFihXFvu60adOwt7c3fDw8PEqiOxWCobS/iZuU9gshhKgSVE2QHB0dMTExyVM9FhcXh6ura77HODk5sXbtWlJTU7lw4QKnTp3CxsYGHx+fAq/j4OBAvXr1OHv2LACurq5kZmaSmJhY6OtOnDiRpKQkwycmJqYIPa249KX9+lVNh7eR0SMhhBBVg6oJkrm5OYGBgYSHhxu26XQ6wsPDad269X2PtbS0pFatWmRnZ7Nq1Sp69+5dYNuUlBQiIyNxc9NPLg4MDMTMzMzouqdPnyY6OrrA61pYWGBnZ2f0qQqWHYwmM1tHk1r2UtovhBCiyjBVO4CwsDCGDRtGixYtaNWqFTNnziQ1NZXQ0FAAhg4dSq1atZg2bRoA+/fv59KlSzRr1oxLly7x3nvvodPpGD9+vOGc48aN44knnsDT05PLly8zdepUTExMGDRoEAD29vY8//zzhIWFUaNGDezs7Hj11Vdp3bo1jz76aNn/EMqp7BwdSwyl/V5S2i+EEKLKUD1BGjBgAFevXmXKlCnExsbSrFkzNm3aZJi4HR0dbTS/KD09ncmTJxMVFYWNjQ0hISEsWbLEaML1xYsXGTRoENeuXcPJyYl27dqxb98+nJycDG2+/PJLtFotffv2JSMjg+DgYL799tsy63dF8OeJOK4kpeNoY06vACntF0IIUXVoFEVR1A6iIkpOTsbe3p6kpKRK+7it/9y9HDh/ndcer0tYt/pqhyOEEEI8tML+/q5wVWyibBy/lMSB87dL+x+VydlCCCGqFkmQRL7uLu13sZPSfiGEEFWLJEgij+upmfz6T25pv5e6wQghhBAqkARJ5PHzAX1pf9Pa9jxSx0HtcIQQQogyJwmSMJKVo2PpPintF0IIUbVJgiSM/PnfndL+nk2ltF8IIUTVJAmSMLJozzkAnm1VBwtTE5WjEUIIIdQhCZIwOH4piYPnb0hpvxBCiCpPEiRhkFvaHyKl/UIIIao4SZAEANdSMu6U9rf1UjcYIYQQQmWSIAkAlh2MITNbR0Bte5p7OKgdjhBCCKEqSZAEWTk6luzVl/YPk9J+IYQQQhIkAX/8F0tsspT2CyGEELkkQRKGydnPBnlKab8QQgiBJEhV3t2l/UOC6qgdjhBCCFEuSIJUxS26PXrUs6kbzlLaL4QQQgCSIFVpCSkZrDt6u7S/jZe6wQghhBDliCRIVdiyA9Fk5twu7a9TXe1whBBCiHJDEqQqKitHx9J90YAsDCmEEELcSxKkKupOab8FIU2ktF8IIYS4myRIVdSi3ecBGBxUR0r7hRBCiHtIglQFHbuYxN8XbmBmomGwlPYLIYQQeUiCVAXllvaHNJHSfiGEECI/kiBVMQkpGfz2j5T2CyGEEPcjCVIVYyjt93CQ0n4hhBCiAJIgVSFZOTqW7LsAQKiMHgkhhBAFkgSpCtl0PJa45AycbKW0XwghhLgfSZCqkNzJ2YOD6mBuKrdeCCGEKIj8lqwijl1M4tDt0v5npbRfCCGEuC9JkKqI3NGjnk3ccLaV0n4hhBDifiRBqgKMSvvbeqscjRBCCFH+lYsEafbs2Xh5eWFpaUlQUBAHDhwosG1WVhYffPABvr6+WFpaEhAQwKZNmwps/+mnn6LRaHjjjTeMtnfq1AmNRmP0efnll0uqS+XKz/v1pf3NPBxo5uGgdjhCCCFEuad6grR8+XLCwsKYOnUqhw8fJiAggODgYOLj4/NtP3nyZObNm8esWbM4ceIEL7/8Mk899RRHjhzJ0/bgwYPMmzePpk2b5nuukSNHcuXKFcPn888/L9G+lQdGpf1tvdQNRgghhKggVE+QZsyYwciRIwkNDaVhw4bMnTsXa2trFixYkG/7JUuWMGnSJEJCQvDx8WHUqFGEhIQwffp0o3YpKSkMHjyY+fPnU716/gsiWltb4+rqavjY2dmVeP/UtvF4LPE39aX9PRpLab8QQghRGKomSJmZmRw6dIguXboYtmm1Wrp06cLevXvzPSYjIwNLS+NJxlZWVuzatcto2+jRo+nZs6fRue/1448/4ujoSOPGjZk4cSJpaWkP0ZvyadHuc4CU9gshhBBFYarmxRMSEsjJycHFxcVou4uLC6dOncr3mODgYGbMmEGHDh3w9fUlPDyc1atXk5OTY2izbNkyDh8+zMGDBwu89rPPPounpyfu7u78+++/vP3225w+fZrVq1fn2z4jI4OMjAzD98nJyUXpqir+vZjI4ehEKe0XQgghikjVBKk4vvrqK0aOHIm/vz8ajQZfX19CQ0MNj+RiYmJ4/fXX2bx5c56Rpru9+OKLhq+bNGmCm5sbnTt3JjIyEl9f3zztp02bxvvvv1/yHSpFuaX9vZq6S2m/EEIIUQSqPnNxdHTExMSEuLg4o+1xcXG4urrme4yTkxNr164lNTWVCxcucOrUKWxsbPDx8QHg0KFDxMfH88gjj2BqaoqpqSk7duzg66+/xtTU1Gik6W5BQUEAnD17Nt/9EydOJCkpyfCJiYkpbrfLxNWbGaz/5woAw+W9a0IIIUSRqJogmZubExgYSHh4uGGbTqcjPDyc1q1b3/dYS0tLatWqRXZ2NqtWraJ3794AdO7cmWPHjnH06FHDp0WLFgwePJijR49iYmKS7/mOHj0KgJtb/hOZLSwssLOzM/qUZz8f0Jf2N6/jQICU9gshhBBFovojtrCwMIYNG0aLFi1o1aoVM2fOJDU1ldDQUACGDh1KrVq1mDZtGgD79+/n0qVLNGvWjEuXLvHee++h0+kYP348ALa2tjRu3NjoGtWqVaNmzZqG7ZGRkfz000+EhIRQs2ZN/v33X8aOHUuHDh0KXBKgIsnM1rH0dmm/jB4JIYQQRad6gjRgwACuXr3KlClTiI2NpVmzZmzatMkwcTs6Ohqt9s5AV3p6OpMnTyYqKgobGxtCQkJYsmQJDg4Ohb6mubk5W7ZsMSRjHh4e9O3bl8mTJ5d091Sx6T8p7RdCCCEehkZRFEXtICqi5ORk7O3tSUpKKneP257+djeHoxMZ26Uer3fxUzscIYQQotwo7O9vWRinkvknRkr7hRBCiIclCVIls/h2af8TTd1xsrVQNxghhBCigpIEqRKJv5nOb/9eBmCYTM4WQgghik0SpErk5/0xZOUoUtovhBBCPCRJkCqJzGwdP+6X0n4hhBCiJEiCVElsPH6F+JsZOEtpvxBCCPHQJEGqJHLfuzbkUU/MTeW2CiGEEA9DfpNWAkdjEjkSnYi5iZZBraS0XwghhHhYkiBVArml/b2auklpvxBCCFECJEGq4OJvprNeSvuFEEKIEiUJUgWXW9r/iJT2CyGEECVGEqQKLDNbx9Lc0v623ipHI4QQQlQekiBVYBuPX+HqzQxc7Czo0dhV7XCEEEKISkMSpAps4e7zAAwO8sTMRG6lEEIIUVLkt2oFdTQmkaMxUtovhBBClAZJkCooQ2l/gJT2CyGEECVNEqQK6O7S/tA2MjlbCCGEKGmSIFVAP+2PJitHIdCzOk1q26sdjhBCCFHpSIJUwWRm61i6LxqA4bIwpBBCCFEqJEGqYH4/doWEFH1pf3cp7RdCCCFKhSRIFcyi25Ozh0hpvxBCCFFq5DdsBXIk+sad0v4gKe0XQgghSoskSBVIbmn/EwHuONpIab8QQghRWiRBqiDik9PZcOwKIJOzhRBCiNImCVIF8aOU9gshhBBlRhKkCiAzW8eP+6W0XwghhCgrkiBVAFLaL4QQQpQtSZAqgIW3J2c/96iU9gshhBBlQX7blnNHom/wT0wi5qZaBrWS0n4hhBCiLEiCVM7lLgz5ZIA7NaW0XwghhCgTkiCVY/HJ6Wz4V0r7hRBCiLJWLhKk2bNn4+XlhaWlJUFBQRw4cKDAtllZWXzwwQf4+vpiaWlJQEAAmzZtKrD9p59+ikaj4Y033jDanp6ezujRo6lZsyY2Njb07duXuLi4kupSifhxfzTZOoUWntVpXEtK+4UQQoiyonqCtHz5csLCwpg6dSqHDx8mICCA4OBg4uPj820/efJk5s2bx6xZszhx4gQvv/wyTz31FEeOHMnT9uDBg8ybN4+mTZvm2Td27Fh+++03Vq5cyY4dO7h8+TJPP/10ifevuDKyc+6U9rf1UjcYIYQQoopRPUGaMWMGI0eOJDQ0lIYNGzJ37lysra1ZsGBBvu2XLFnCpEmTCAkJwcfHh1GjRhESEsL06dON2qWkpDB48GDmz59P9erVjfYlJSXx/fffM2PGDB5//HECAwNZuHAhe/bsYd++faXW16LILe13tbMkuJGU9gshhBBlSdUEKTMzk0OHDtGlSxfDNq1WS5cuXdi7d2++x2RkZGBpaWm0zcrKil27dhltGz16ND179jQ6d65Dhw6RlZVltM/f3586deoUeN2ypCgKC3efB+C51lLaL4QQQpQ1UzUvnpCQQE5ODi4uLkbbXVxcOHXqVL7HBAcHM2PGDDp06ICvry/h4eGsXr2anJwcQ5tly5Zx+PBhDh48mO85YmNjMTc3x8HBIc91Y2Nj8z0mIyODjIwMw/fJycmF6WKxHIlJ5N+LSZibahnY0qPUriOEEEKI/FW4oYmvvvoKPz8//P39MTc3Z8yYMYSGhqLV6rsSExPD66+/zo8//phnpOlhTJs2DXt7e8PHw6P0EpdFt0ePpLRfCCGEUIeqCZKjoyMmJiZ5qsfi4uJwdc1/3o2TkxNr164lNTWVCxcucOrUKWxsbPDx8QH0j8/i4+N55JFHMDU1xdTUlB07dvD1119jampKTk4Orq6uZGZmkpiYWOjrTpw4kaSkJMMnJibm4X8A+YhLTuf3Y1LaL4QQQqhJ1QTJ3NycwMBAwsPDDdt0Oh3h4eG0bt36vsdaWlpSq1YtsrOzWbVqFb179wagc+fOHDt2jKNHjxo+LVq0YPDgwRw9ehQTExMCAwMxMzMzuu7p06eJjo4u8LoWFhbY2dkZfUpDbml/Sy8p7RdCCCHUouocJICwsDCGDRtGixYtaNWqFTNnziQ1NZXQ0FAAhg4dSq1atZg2bRoA+/fv59KlSzRr1oxLly7x3nvvodPpGD9+PAC2trY0btzY6BrVqlWjZs2ahu329vY8//zzhIWFUaNGDezs7Hj11Vdp3bo1jz76aBn2Pq/kW1mYajUMb+OtahxCCCFEVaZ6gjRgwACuXr3KlClTiI2NpVmzZmzatMkwcTs6Otowvwj0CzxOnjyZqKgobGxsCAkJYcmSJXkmXD/Il19+iVarpW/fvmRkZBAcHMy3335bkl0rlveebMSoTr7UqGaudihCCCFElaVRFEVRO4iKKDk5GXt7e5KSkkrtcZsQQgghSlZhf39XuCo2IYQQQojSJgmSEEIIIcQ9JEESQgghhLiHJEhCCCGEEPeQBEkIIYQQ4h6SIAkhhBBC3EMSJCGEEEKIe0iCJIQQQghxD0mQhBBCCCHuIQmSEEIIIcQ9JEESQgghhLiHJEhCCCGEEPeQBEkIIYQQ4h6magdQUSmKAujfCiyEEEKIiiH393bu7/GCSIJUTDdv3gTAw8ND5UiEEEIIUVQ3b97E3t6+wP0a5UEplMiXTqfj8uXL2NraotFoSuy8ycnJeHh4EBMTg52dXYmdtzyp7H2s7P2Dyt9H6V/FV9n7KP0rPkVRuHnzJu7u7mi1Bc80khGkYtJqtdSuXbvUzm9nZ1cp/9HfrbL3sbL3Dyp/H6V/FV9l76P0r3juN3KUSyZpCyGEEELcQxIkIYQQQoh7SIJUzlhYWDB16lQsLCzUDqXUVPY+Vvb+QeXvo/Sv4qvsfZT+lT6ZpC2EEEIIcQ8ZQRJCCCGEuIckSEIIIYQQ95AESQghhBDiHpIgCSGEEELcQxKkMvbXX3/xxBNP4O7ujkajYe3atQ88Zvv27TzyyCNYWFhQt25dFi1aVOpxFldR+7d9+3Y0Gk2eT2xsbNkEXETTpk2jZcuW2Nra4uzsTJ8+fTh9+vQDj1u5ciX+/v5YWlrSpEkTfv/99zKItniK08dFixbluYeWlpZlFHHRzJkzh6ZNmxoWoGvdujUbN2687zEV6f4VtX8V6d7l59NPP0Wj0fDGG2/ct11Fuof3KkwfK9J9fO+99/LE6u/vf99j1Lh/kiCVsdTUVAICApg9e3ah2p87d46ePXvy2GOPcfToUd544w1eeOEF/vjjj1KOtHiK2r9cp0+f5sqVK4aPs7NzKUX4cHbs2MHo0aPZt28fmzdvJisri27dupGamlrgMXv27GHQoEE8//zzHDlyhD59+tCnTx+OHz9ehpEXXnH6CPoVb+++hxcuXCijiIumdu3afPrppxw6dIi///6bxx9/nN69e/Pff//l276i3b+i9g8qzr2718GDB5k3bx5Nmza9b7uKdg/vVtg+QsW6j40aNTKKddeuXQW2Ve3+KUI1gLJmzZr7thk/frzSqFEjo20DBgxQgoODSzGyklGY/m3btk0BlBs3bpRJTCUtPj5eAZQdO3YU2KZ///5Kz549jbYFBQUpL730UmmHVyIK08eFCxcq9vb2ZRdUCatevbryf//3f/nuq+j3T1Hu37+Keu9u3ryp+Pn5KZs3b1Y6duyovP766wW2raj3sCh9rEj3cerUqUpAQECh26t1/2QEqZzbu3cvXbp0MdoWHBzM3r17VYqodDRr1gw3Nze6du3K7t271Q6n0JKSkgCoUaNGgW0q+j0sTB8BUlJS8PT0xMPD44EjFuVFTk4Oy5YtIzU1ldatW+fbpiLfv8L0DyrmvRs9ejQ9e/bMc2/yU1HvYVH6CBXrPkZERODu7o6Pjw+DBw8mOjq6wLZq3T95WW05Fxsbi4uLi9E2FxcXkpOTuXXrFlZWVipFVjLc3NyYO3cuLVq0ICMjg//7v/+jU6dO7N+/n0ceeUTt8O5Lp9Pxxhtv0LZtWxo3blxgu4LuYXmdZ3W3wvaxfv36LFiwgKZNm5KUlMQXX3xBmzZt+O+//0r1pc7FdezYMVq3bk16ejo2NjasWbOGhg0b5tu2It6/ovSvot07gGXLlnH48GEOHjxYqPYV8R4WtY8V6T4GBQWxaNEi6tevz5UrV3j//fdp3749x48fx9bWNk97te6fJEhCVfXr16d+/fqG79u0aUNkZCRffvklS5YsUTGyBxs9ejTHjx+/77Pziq6wfWzdurXRCEWbNm1o0KAB8+bN48MPPyztMIusfv36HD16lKSkJH755ReGDRvGjh07CkwiKpqi9K+i3buYmBhef/11Nm/eXG4nIT+s4vSxIt3HHj16GL5u2rQpQUFBeHp6smLFCp5//nkVIzMmCVI55+rqSlxcnNG2uLg47OzsKvzoUUFatWpV7pOOMWPGsH79ev76668H/nVW0D10dXUtzRAfWlH6eC8zMzOaN2/O2bNnSym6h2Nubk7dunUBCAwM5ODBg3z11VfMmzcvT9uKeP+K0r97lfd7d+jQIeLj441GmHNycvjrr7/45ptvyMjIwMTExOiYinYPi9PHe5X3+3g3BwcH6tWrV2Csat0/mYNUzrVu3Zrw8HCjbZs3b77vfIKK7ujRo7i5uakdRr4URWHMmDGsWbOGrVu34u3t/cBjKto9LE4f75WTk8OxY8fK7X28l06nIyMjI999Fe3+5ed+/btXeb93nTt35tixYxw9etTwadGiBYMHD+bo0aP5Jg4V7R4Wp4/3Ku/38W4pKSlERkYWGKtq969Up4CLPG7evKkcOXJEOXLkiAIoM2bMUI4cOaJcuHBBURRFmTBhgvLcc88Z2kdFRSnW1tbKW2+9pZw8eVKZPXu2YmJiomzatEmtLtxXUfv35ZdfKmvXrlUiIiKUY8eOKa+//rqi1WqVLVu2qNWF+xo1apRib2+vbN++Xbly5Yrhk5aWZmjz3HPPKRMmTDB8v3v3bsXU1FT54osvlJMnTypTp05VzMzMlGPHjqnRhQcqTh/ff/995Y8//lAiIyOVQ4cOKQMHDlQsLS2V//77T40u3NeECROUHTt2KOfOnVP+/fdfZcKECYpGo1H+/PNPRVEq/v0rav8q0r0ryL0VXhX9HubnQX2sSPfxzTffVLZv366cO3dO2b17t9KlSxfF0dFRiY+PVxSl/Nw/SZDKWG5Z+72fYcOGKYqiKMOGDVM6duyY55hmzZop5ubmio+Pj7Jw4cIyj7uwitq/zz77TPH19VUsLS2VGjVqKJ06dVK2bt2qTvCFkF/fAKN70rFjR0N/c61YsUKpV6+eYm5urjRq1EjZsGFD2QZeBMXp4xtvvKHUqVNHMTc3V1xcXJSQkBDl8OHDZR98IYwYMULx9PRUzM3NFScnJ6Vz586G5EFRKv79K2r/KtK9K8i9yUNFv4f5eVAfK9J9HDBggOLm5qaYm5srtWrVUgYMGKCcPXvWsL+83D+NoihK6Y5RCSGEEEJULDIHSQghhBDiHpIgCSGEEELcQxIkIYQQQoh7SIIkhBBCCHEPSZCEEEIIIe4hCZIQQgghxD0kQRJCCCGEuIckSEIIUUwajYa1a9eqHYYQohRIgiSEqJCGDx+ORqPJ8+nevbvaoQkhKgFTtQMQQoji6t69OwsXLjTaZmFhoVI0QojKREaQhBAVloWFBa6urkaf6tWrA/rHX3PmzKFHjx5Y/X979xPK/h/HAfw5f776bFFjozlJtEZxQJo/BxRNKZqkPumTyzKzXFzk/8FNuK1WnMhqSi2McFSiZFbGjYsW4mArLnv/Dr9abfr90tf4fun5qNXn/X59/rw+Oz37fN5rkoTi4mKsr68nHB8MBtHc3AxJkpCXlwebzYZIJJKwz/LyMsrLy5GVlQWDwYChoaGE+sPDA7q6uqBWq1FaWgqfzxevPT09QZZl6PV6SJKE0tLSN4GOiP5ODEhE9GNNTEzAarUiEAhAlmX09vYiFAoBAKLRKNra2qDVanFycgKv14v9/f2EAORyueBwOGCz2RAMBuHz+VBSUpJwjZmZGfT09OD8/Bzt7e2QZRmPj4/x619cXMDv9yMUCsHlckGn033dF0BEv+/T/w6XiOgTKIoi0tPThUajSfjMzs4KIYQAIAYGBhKOqa2tFXa7XQghhNvtFlqtVkQikXh9a2tLpKWliXA4LIQQorCwUIyNjf1nDwDE+Ph4fByJRAQA4ff7hRBCdHR0iP7+/tTcMBF9Ka5BIqJvq6mpCS6XK2EuNzc3vm02mxNqZrMZZ2dnAIBQKITKykpoNJp4vb6+HrFYDFdXV1CpVLi9vUVLS8v/9lBRURHf1mg0yMnJwd3dHQDAbrfDarXi9PQUra2t6OzsRF1d3W/dKxF9LQYkIvq2NBrNm1deqSJJ0rv2y8zMTBirVCrEYjEAgMViwc3NDba3t7G3t4eWlhY4HA7Mzc2lvF8iSi2uQSKiH+vo6OjN2GQyAQBMJhMCgQCi0Wi8fnh4iLS0NBiNRmRnZ6OoqAgHBwcf6kGv10NRFKysrGBxcRFut/tD5yOir8EnSET0bb2+viIcDifMZWRkxBdCe71eVFdXo6GhAaurqzg+PsbS0hIAQJZlTE1NQVEUTE9P4/7+Hk6nE319fSgoKAAATE9PY2BgAPn5+bBYLHh+fsbh4SGcTue7+pucnERVVRXKy8vx+vqKzc3NeEAjor8bAxIRfVs7OzswGAwJc0ajEZeXlwD+/YWZx+PB4OAgDAYD1tbWUFZWBgBQq9XY3d3F8PAwampqoFarYbVaMT8/Hz+Xoih4eXnBwsICRkZGoNPp0N3d/e7+fv36hdHRUVxfX0OSJDQ2NsLj8aTgzonos6mEEOJPN0FElGoqlQobGxvo7Oz8060Q0TfENUhERERESRiQiIiIiJJwDRIR/UhcPUBEH8EnSERERERJGJCIiIiIkjAgERERESVhQCIiIiJKwoBERERElIQBiYiIiCgJAxIRERFREgYkIiIioiQMSERERERJ/gHRbVcEwxUFUgAAAABJRU5ErkJggg=="},"metadata":{}}]},{"cell_type":"code","source":"def align_word_ids(texts):\n  \n    tokenized_inputs = tokenizer(texts, padding='max_length', max_length=512, truncation=True)\n\n    word_ids = tokenized_inputs.word_ids()\n\n    previous_word_idx = None\n    label_ids = []\n\n    for word_idx in word_ids:\n\n        if word_idx is None:\n            label_ids.append(-100)\n\n        elif word_idx != previous_word_idx:\n            try:\n                label_ids.append(1)\n            except:\n                label_ids.append(-100)\n        else:\n            try:\n                label_ids.append(1 if label_all_tokens else -100)\n            except:\n                label_ids.append(-100)\n        previous_word_idx = word_idx\n\n    return label_ids\n\n\ndef evaluate_one_text(model, sentence):\n\n\n    use_cuda = torch.cuda.is_available()\n    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n\n    if use_cuda:\n        model = model.cuda()\n\n    text = tokenizer(sentence, padding='max_length', max_length = 512, truncation=True, return_tensors=\"pt\")\n\n    mask = text['attention_mask'].to(device)\n    input_id = text['input_ids'].to(device)\n    label_ids = torch.Tensor(align_word_ids(sentence)).unsqueeze(0).to(device)\n\n    logits = model(input_id, mask, None)\n    logits_clean = logits[0][label_ids != -100]\n\n    predictions = logits_clean.argmax(dim=1).tolist()\n    prediction_label = [ids_to_labels[i] for i in predictions]\n    print(sentence)\n    print(prediction_label)\nevaluate_one_text(model, 'Bill Gates es el fundador de la organización Microsoft')","metadata":{"execution":{"iopub.status.busy":"2023-05-08T07:05:29.017011Z","iopub.execute_input":"2023-05-08T07:05:29.017672Z","iopub.status.idle":"2023-05-08T07:05:29.070970Z","shell.execute_reply.started":"2023-05-08T07:05:29.017637Z","shell.execute_reply":"2023-05-08T07:05:29.069588Z"},"trusted":true},"execution_count":24,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[24], line 52\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mprint\u001b[39m(sentence)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28mprint\u001b[39m(prediction_label)\n\u001b[0;32m---> 52\u001b[0m \u001b[43mevaluate_one_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBill Gates es el fundador de la organización Microsoft\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[24], line 39\u001b[0m, in \u001b[0;36mevaluate_one_text\u001b[0;34m(model, sentence)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cuda:\n\u001b[1;32m     37\u001b[0m     model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m---> 39\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m(sentence, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m'\u001b[39m, max_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m512\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m mask \u001b[38;5;241m=\u001b[39m text[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     42\u001b[0m input_id \u001b[38;5;241m=\u001b[39m text[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n","\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"],"ename":"NameError","evalue":"name 'tokenizer' is not defined","output_type":"error"}]},{"cell_type":"code","source":"evaluate_one_text(model, \"\")","metadata":{"execution":{"iopub.status.busy":"2023-05-08T03:06:43.653238Z","iopub.status.idle":"2023-05-08T03:06:43.654006Z","shell.execute_reply.started":"2023-05-08T03:06:43.653761Z","shell.execute_reply":"2023-05-08T03:06:43.653783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}